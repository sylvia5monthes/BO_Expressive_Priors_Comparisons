{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed841451-2ad2-4a82-8b8d-e8cc8904736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN Surrogate model class\n",
    "import injector_surrogate_quads\n",
    "from injector_surrogate_quads import *\n",
    "import physics_gp\n",
    "\n",
    "sys.path.append('../configs')\n",
    "#Sim reference point to optimize around\n",
    "from ref_config import ref_point\n",
    "\n",
    "#Pytorch \n",
    "import numpy as np\n",
    "import torch\n",
    "import transformer\n",
    "import gpytorch\n",
    "import botorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9dd34-10e0-4915-accf-957a40d4f47b",
   "metadata": {},
   "source": [
    "# BO for Minimizing Emittance*Bmag with 9 Variables (SQ, CQ, SOL, matching quads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ef807c-db73-418f-adfb-66d40cc2124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 11:27:54.632738: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#load injector model\n",
    "Model = Surrogate_NN()\n",
    "\n",
    "Model.load_saved_model(model_path = '../models/', \\\n",
    "                       model_name = 'model_OTR2_NA_rms_emit_elu_2021-07-27T19_54_57-07_00')\n",
    "Model.load_scaling()\n",
    "Model.take_log_out = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee602f2-7593-4ddf-b836-2e7ce051d196",
   "metadata": {},
   "source": [
    "## Import design Twiss parameters (OTR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e7b392-8239-41c9-adbe-1c1f234db566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-06, 1.113081026, -0.0689403587]\n",
      "[1e-06, 1.113021659, -0.07029489754]\n"
     ]
    }
   ],
   "source": [
    "beamline_info = json.load(open('../configs/beamline_info.json'))\n",
    "get_twiss0 = beamline_info['Twiss0']\n",
    "# emit, beta, alpha\n",
    "twiss0 = {'x': [get_twiss0[0], get_twiss0[2], get_twiss0[4]],\n",
    "          'y': [get_twiss0[1], get_twiss0[3], get_twiss0[5]]}\n",
    "\n",
    "beta0_x, alpha0_x = twiss0['x'][1], twiss0['x'][2]\n",
    "beta0_y, alpha0_y = twiss0['y'][1], twiss0['y'][2]\n",
    "print(twiss0['x'])\n",
    "print(twiss0['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d0ea5-fda2-4658-bcc0-0f89757ffeb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712a59e5-3b68-4c92-b4d8-fc7f122feec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to machine units\n",
    "ref_point = Model.sim_to_machine(np.asarray(ref_point))\n",
    "\n",
    "# input params: solenoid and quads to vary \n",
    "opt_var_names = ['SOL1:solenoid_field_scale','CQ01:b1_gradient', 'SQ01:b1_gradient',\n",
    "                 \"QA01:b1_gradient\", \"QA02:b1_gradient\", \n",
    "                 \"QE01:b1_gradient\", \"QE02:b1_gradient\", \"QE03:b1_gradient\", \"QE04:b1_gradient\"]\n",
    "\n",
    "# output params: emittance in transverse plane (x & y)\n",
    "opt_out_names = ['norm_emit_x','norm_emit_y']\n",
    "\n",
    "def evaluate(varx, vary, varz, var1, var2, var3, var4, var5, var6): \n",
    "    \"\"\"\n",
    "    vars: sol, cq, sq, qa1, qa2, q1, q2, q3, q4\n",
    "    \"\"\" \n",
    "    # make input array of length model_in_list (inputs model takes)\n",
    "    x_in = np.empty((1,len(Model.model_in_list)))\n",
    "\n",
    "    # fill in reference point around which to optimize\n",
    "    x_in[:,:] = np.asarray(ref_point[0])\n",
    "\n",
    "    # set solenoid, SQ, CQ to values from optimization step\n",
    "    x_in[:, Model.loc_in[opt_var_names[0]]] = varx\n",
    "    x_in[:, Model.loc_in[opt_var_names[1]]] = vary\n",
    "    x_in[:, Model.loc_in[opt_var_names[2]]] = varz\n",
    "    x_in[:, Model.loc_in[opt_var_names[3]]] = var1\n",
    "    x_in[:, Model.loc_in[opt_var_names[4]]] = var2\n",
    "    x_in[:, Model.loc_in[opt_var_names[5]]] = var3\n",
    "    x_in[:, Model.loc_in[opt_var_names[6]]] = var4\n",
    "    x_in[:, Model.loc_in[opt_var_names[7]]] = var5\n",
    "    x_in[:, Model.loc_in[opt_var_names[8]]] = var6\n",
    "\n",
    "    # output predictions\n",
    "    y_out = Model.pred_machine_units(x_in) \n",
    "\n",
    "    return -1*objective(y_out)[0]\n",
    "\n",
    "\n",
    "\n",
    "def objective(y_out):\n",
    "    \n",
    "    # output is geometric emittance in transverse plane\n",
    "    out1 = y_out[:, Model.loc_out['norm_emit_x']] #grab norm_emit_x out of the model\n",
    "    out2 = y_out[:, Model.loc_out['norm_emit_y']] #grab norm_emit_y out of the model\n",
    "    emit = np.sqrt(out1 * out2)\n",
    "  \n",
    "    sigma_x = y_out[:, Model.loc_out['sigma_x']] #grab sigma_x out of the model \n",
    "    sigma_y = y_out[:, Model.loc_out['sigma_y']] #grab sigma_y out of the model \n",
    "    \n",
    "    # real beta and alpha \n",
    "    # NEEDS TO BE FIXED - currently assuming real alpha to be the same as design alpha \n",
    "    alpha_x, alpha_y = alpha0_x, alpha0_y\n",
    "    beta_x, beta_y = (sigma_x**2) / out1, (sigma_y**2) / out2\n",
    "    \n",
    "    # bmag \n",
    "    bmag_x = 0.5 * ((beta0_x / beta_x) + (beta_x / beta0_x)) + 0.5 * (alpha_x * np.sqrt(beta0_x / beta_x) - alpha0_x * np.sqrt(beta_x / beta0_x))\n",
    "    bmag_y = 0.5 * ((beta0_y / beta_y) + (beta_y / beta0_y)) + 0.5 * (alpha_y * np.sqrt(beta0_y / beta_y) - alpha0_y * np.sqrt(beta_y / beta0_y))\n",
    "    bmag = np.sqrt(bmag_x * bmag_y)\n",
    "    print(f'bmag: {bmag} emit: {emit}') \n",
    "    \n",
    "    return (emit * bmag)/1e-6\n",
    "    #return np.sqrt(out1*out2)/1e-6 # in um units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95895f93-be9f-4fd1-b50c-ba4d488269bb",
   "metadata": {},
   "source": [
    "## Gaussian Regression & Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3579279b-21fd-4afc-b7b3-33b0fd38ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BO_point(x, f, bounds, beta=2.5, precision = None, phys=True):\n",
    "    \"\"\"\n",
    "    function that trains a GP model of data and returns the next observation point using UCB\n",
    "    D is input space dimensionality\n",
    "    N is number of samples\n",
    "\n",
    "    :param x: input points data, torch.tensor, shape (N,D)\n",
    "    :param f: output point data, torch.tensor, shape (N,1)\n",
    "    :param bounds: input space bounds, torch.tensor, shape (2,D)\n",
    "    :param precision: precision matrix used for RBF kernel (must be PSD), torch.tensor, (D,D)\n",
    "    :param beta: UCB optimization parameter, float\n",
    "    :return x_candidate, model: next observation point and gp model w/observations\n",
    "    \"\"\"\n",
    "    \n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    \n",
    "    if phys == True:\n",
    "        gp = physics_gp.PhysicsExactGPModel(x, f.flatten(), likelihood, precision)\n",
    "    else:\n",
    "        gp = botorch.models.SingleTaskGP(x, f, likelihood)\n",
    "        \n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    \n",
    "    # fit GP hyperparameters\n",
    "    #print('training hyperparameters')\n",
    "    botorch.fit.fit_gpytorch_model(mll)\n",
    "\n",
    "    # do UCB acquisition\n",
    "    #print('optimizing acquisition function')\n",
    "    UCB = botorch.acquisition.UpperConfidenceBound(gp, beta=beta)\n",
    "    candidate, acq_value = botorch.optim.optimize_acqf(UCB,\n",
    "                                                       bounds=bounds,\n",
    "                                                       q=1,\n",
    "                                                       num_restarts=20,#5\n",
    "                                                       raw_samples=20)\n",
    "    return candidate, gp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab76dc5-7177-4a05-8133-4639cf66ae38",
   "metadata": {},
   "source": [
    "## Set up initial training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8e2cc5-715b-415d-a9c4-3d92e183d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.6418e-01, -1.9117e-03, -1.3368e-03, -1.9305e+00,  3.9036e+00,\n",
      "         -3.0059e+00,  8.2373e-01,  5.7331e+00, -2.4869e+00],\n",
      "        [ 4.6736e-01, -1.5112e-02, -1.5957e-03, -1.7717e+00,  2.4311e+00,\n",
      "         -4.4188e+00,  1.8396e+00,  8.5522e-01, -2.7316e+00],\n",
      "        [ 4.6643e-01,  1.8102e-02,  1.1459e-03, -2.6752e+00,  1.7924e+00,\n",
      "         -4.5148e+00,  6.9346e+00, -8.0024e-01,  2.8992e-01],\n",
      "        [ 4.6132e-01,  3.5913e-03, -1.2952e-02, -3.6826e+00,  3.7173e+00,\n",
      "         -4.7937e+00,  1.2303e+00,  3.9029e+00, -1.0695e+00],\n",
      "        [ 4.7832e-01, -6.9391e-03, -4.8378e-03, -1.1993e+00,  3.7667e+00,\n",
      "         -6.5673e+00,  5.3081e+00,  5.5752e+00, -5.1483e+00]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 11:28:02.590471: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-14 11:28:02.615443: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1996075000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmag: [1.5233376] emit: [1.069796e-06]\n",
      "bmag: [1.6119298] emit: [1.081863e-06]\n",
      "bmag: [2.5465887] emit: [1.4116972e-06]\n",
      "bmag: [3.7971401] emit: [1.1632793e-06]\n",
      "bmag: [1.0842239] emit: [8.529898e-07]\n",
      "tensor([[-1.6297],\n",
      "        [-1.7439],\n",
      "        [-3.5950],\n",
      "        [-4.4171],\n",
      "        [-0.9248]])\n",
      "[ 0.46 -0.02 -0.02 -4.    1.   -7.   -1.   -1.   -7.  ]\n",
      "[ 0.485  0.02   0.02  -1.     4.    -1.     7.     7.     1.   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n#create initial model\\ngp = SingleTaskGP(normed_train_x, normed_train_y)\\nmll = ExactMarginalLogLikelihood(gp.likelihood, gp)\\nfit_gpytorch_model(mll);\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specify bounds\n",
    "bounds = {'varx': (0.46, 0.485),\n",
    "          'vary': (-0.02, 0.02),\n",
    "          'varz': (-0.02, 0.02),\n",
    "          'var1': (-4, -1),\n",
    "          'var2': (1, 4),\n",
    "          'var3': (-7, -1),\n",
    "          'var4': (-1, 7),\n",
    "          'var5': (-1, 7),\n",
    "          'var6': (-7, 1)}\n",
    "                        \n",
    "tbounds = torch.tensor([[bounds['varx'][0], bounds['varx'][1]],\n",
    "                        [bounds['vary'][0], bounds['vary'][1]], \n",
    "                        [bounds['varz'][0], bounds['varz'][1]],\n",
    "                        [bounds['var1'][0], bounds['var1'][1]],\n",
    "                        [bounds['var2'][0], bounds['var2'][1]],\n",
    "                        [bounds['var3'][0], bounds['var3'][1]],\n",
    "                        [bounds['var4'][0], bounds['var4'][1]],\n",
    "                        [bounds['var5'][0], bounds['var5'][1]],\n",
    "                        [bounds['var6'][0], bounds['var6'][1]]])\n",
    "\n",
    "#print(bounds['varx'][0])\n",
    "#print(tbounds)\n",
    "\n",
    "#create initial samples within specified bounds\n",
    "n_samples = 5\n",
    "n_var = 9\n",
    "train_x = torch.zeros((n_samples, n_var)) \n",
    "for i in range(n_var):\n",
    "    train_x[:,i] = torch.as_tensor(np.random.uniform(tbounds[i,0],tbounds[i,1],(n_samples,)))\n",
    "#train_x = torch.as_tensor(train_x).type(torch.FloatTensor)\n",
    "\n",
    "\"\"\"\n",
    "train_x = torch.rand(n_samples,3) \n",
    "train_x[:,0] = train_x[:,0] * diff['varx'] + bounds['varx'][0]\n",
    "train_x[:,1] = train_x[:,1] * diff['vary'] + bounds['vary'][0]\n",
    "train_x[:,2] = train_x[:,2] * diff['varz'] + bounds['varz'][0]\n",
    "\"\"\" \n",
    "print(train_x)\n",
    "\n",
    "train_y = torch.tensor([evaluate(vars[0], vars[1], vars[2], vars[3], vars[4], vars[5], vars[6], vars[7], vars[8]) for vars in train_x]).reshape(-1,1)\n",
    "print(train_y)\n",
    "\n",
    "\n",
    "#transformer \n",
    "transformer_x = transformer.Transformer(tbounds.transpose(0,1), transform_type = 'normalize')\n",
    "print(transformer_x.mins)\n",
    "print(transformer_x.maxs)\n",
    "normed_train_x = transformer_x.forward(train_x)\n",
    "\n",
    "transformer_y = transformer.Transformer(train_y, transform_type = 'standardize') \n",
    "normed_train_y = transformer_y.forward(train_y)\n",
    "\n",
    "\"\"\" \n",
    "#create initial model\n",
    "gp = SingleTaskGP(normed_train_x, normed_train_y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_model(mll);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7ebe7-3652-467a-aabd-9c285ecc7dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f08ef8-0cde-4c86-8e5b-57c8ac264e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmag: [1.913289] emit: [7.68876e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m1      -1.47108   0.47377   -0.00776   -0.00276   -1.31384   3.60709   -5.33280   3.73193   5.02076   -4.32158\u001b[0m\n",
      "bmag: [1.9754714] emit: [8.7927197e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m2      -1.73698   0.47861   -0.01221   -0.00529   -1.22854   3.23794   -6.96081   5.31290   3.74318   -5.11190\u001b[0m\n",
      "bmag: [1.1159384] emit: [1.1442831e-06]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m3      -1.27695   0.47844   -0.00741   -0.00912   -1.35550   4.00000   -6.30907   3.79619   6.82383   -6.09028\u001b[0m\n",
      "bmag: [2.602773] emit: [1.1662045e-06]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m4      -3.03537   0.48010   -0.00522   -0.00075   -1.25901   4.00000   -6.79833   4.41147   6.98475   -3.80192\u001b[0m\n",
      "bmag: [4.0227084] emit: [8.287227e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m5      -3.33371   0.47500   -0.00573   -0.00802   -1.17155   3.80387   -5.73368   5.66589   5.11974   -6.22500\u001b[0m\n",
      "bmag: [1.5451272] emit: [1.1046519e-06]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m6      -1.70683   0.47913   -0.01112   -0.00668   -1.38400   3.64312   -6.60771   3.25625   5.88289   -5.23310\u001b[0m\n",
      "bmag: [1.2199652] emit: [1.4073972e-06]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m7      -1.71698   0.48275   -0.00820   -0.00757   -1.26661   3.86368   -7.00000   5.40154   6.37279   -5.71560\u001b[0m\n",
      "bmag: [1.1701708] emit: [8.40181e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m8      -0.98316   0.47605   -0.00462   -0.00836   -1.66640   3.86239   -7.00000   4.86027   5.70744   -5.00977\u001b[0m\n",
      "bmag: [1.8366492] emit: [9.1171694e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m9      -1.67450   0.47522   -0.00323   -0.00456   -1.15377   4.00000   -7.00000   4.32404   6.95857   -5.33017\u001b[0m\n",
      "bmag: [1.3380198] emit: [7.589852e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m10      -1.01554   0.47871   -0.00641   -0.00472   -1.79304   4.00000   -5.93789   5.07075   4.92267   -4.88164\u001b[0m\n",
      "bmag: [1.4284159] emit: [9.301587e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m11      -1.32865   0.47743   -0.00783   -0.01215   -1.37481   3.70625   -5.81810   5.22825   5.63379   -4.77310\u001b[0m\n",
      "bmag: [1.3000709] emit: [6.1248943e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[95m12      -0.79628   0.47751   -0.00365   -0.00179   -1.74692   3.33494   -6.32853   5.10788   5.52246   -4.95246\u001b[0m\n",
      "bmag: [2.0254462] emit: [7.3105787e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m13      -1.48072   0.47873   0.00091   -0.00483   -1.36791   3.58956   -6.49871   4.74871   4.79926   -4.93262\u001b[0m\n",
      "bmag: [1.1219971] emit: [7.445139e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m14      -0.83534   0.47491   -0.01039   0.00045   -1.77594   3.67113   -6.53228   5.37728   5.64939   -4.90651\u001b[0m\n",
      "bmag: [1.045266] emit: [7.22381e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[95m15      -0.75508   0.47828   -0.00894   -0.00302   -2.07391   3.66584   -6.13774   5.04401   6.35647   -5.21464\u001b[0m\n",
      "bmag: [3.6182573] emit: [7.077362e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m16      -2.56077   0.47400   -0.00810   -0.00309   -2.07327   3.47424   -5.66109   4.56678   5.63724   -5.03983\u001b[0m\n",
      "bmag: [1.0251685] emit: [7.175734e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[95m17      -0.73563   0.47782   -0.00881   -0.00049   -1.93329   3.83307   -6.81558   6.23689   6.11970   -5.05171\u001b[0m\n",
      "bmag: [1.0965971] emit: [7.33622e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m18      -0.80449   0.47750   -0.00927   0.00432   -1.74772   3.98760   -6.60682   5.00643   5.77947   -5.16398\u001b[0m\n",
      "bmag: [1.0119486] emit: [8.367399e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m19      -0.84674   0.47738   -0.01333   -0.00279   -1.72887   3.59448   -6.50084   5.57462   6.09360   -4.80676\u001b[0m\n",
      "bmag: [1.0916439] emit: [8.562893e-07]\n",
      "iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\n",
      "\u001b[30m20      -0.93476   0.47865   -0.00422   -0.00746   -1.91982   4.00000   -6.52564   5.50718   6.80065   -5.40651\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "n_steps = 20\n",
    "best_y = torch.max(train_y)\n",
    "for i in range(n_steps):\n",
    "    if i > 10:\n",
    "        phys_l = True\n",
    "        \n",
    "    bounds = torch.cat((torch.zeros(1,n_var), torch.ones(1,n_var)), 0)\n",
    "    #x_new, model = get_BO_point(train_x, normed_train_y, bounds=tbounds.transpose(0,1), phys = False)\n",
    "    x_new, model = get_BO_point(normed_train_x, normed_train_y, bounds=bounds, phys = False)\n",
    "    \n",
    "    #train_x = torch.cat((train_x, x_new))\n",
    "    train_x = torch.cat((train_x, transformer_x.backward(x_new)))\n",
    "    normed_train_x = transformer_x.forward(train_x)\n",
    "    \n",
    "    new_y = torch.tensor(evaluate(train_x[-1,0], train_x[-1,1], train_x[-1,2], \n",
    "                                 train_x[-1,3], train_x[-1,4], train_x[-1,5],\n",
    "                                 train_x[-1,6], train_x[-1,7], train_x[-1,8])).reshape(1,1)\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    normed_train_y = transformer_y.forward(train_y)\n",
    "    \n",
    "    train_x = train_x.type(torch.FloatTensor)\n",
    "    train_y = train_y.type(torch.FloatTensor)\n",
    "    \n",
    "    if (new_y > best_y):\n",
    "        best_y = new_y\n",
    "        color = '\\033[95m', '\\033[0m'\n",
    "    else: \n",
    "        color = '\\u001b[30m', '\\033[0m'\n",
    "    \n",
    "    print(\"iter     target      varx       vary      varz      var1      var2      var3      var4      var5      var6\")\n",
    "    print(f'{color[0]}{i+1}      {train_y[-1,0]:.5f}   {train_x[-1,0]:.5f}   {train_x[-1,1]:.5f}   {train_x[-1,2]:.5f}   {train_x[-1,3]:.5f}   {train_x[-1,4]:.5f}   {train_x[-1,5]:.5f}   {train_x[-1,6]:.5f}   {train_x[-1,7]:.5f}   {train_x[-1,8]:.5f}{color[1]}')\n",
    "    #print(f'max = {torch.max(train_y):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a950e-7da0-4c8c-8f01-42becd03cb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6448337-8ec1-48f0-bbae-5cd1106dbf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#define acquisition function\\nfrom botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\\nfrom botorch.optim import optimize_acqf\\n\\n#optimize\\nn_steps = 45\\nfor i in range(n_steps):\\n    #best_normed_y = torch.max(normed_train_y)\\n    UCB = UpperConfidenceBound(gp, beta=2.5)\\n    #EI = ExpectedImprovement(gp, best_normed_y)\\n\\n    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\\n    candidate, acq_value = optimize_acqf(UCB, bounds = bounds, num_restarts = 20, q = 1, raw_samples = 20)\\n\\n    train_x = torch.cat((train_x, transformer_x.backward(candidate)))\\n    normed_train_x = transformer_x.forward(train_x)\\n\\n    new_y = torch.tensor(evaluate(train_x[-1][0], train_x[-1][1], train_x[-1][2])).reshape(1,1)\\n    train_y = torch.cat((train_y, new_y))\\n    \\n    print(\"iteration        target         varx         vary         varz\")\\n    print(f\\'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}\\')\\n    print(torch.max(train_y))\\n    \\n    transformer_y = transformer.Transformer(train_y, \\'standardize\\')\\n    normed_train_y = transformer_y.forward(train_y)\\n\\n    gp = SingleTaskGP(normed_train_x, normed_train_y)\\n    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\\n    fit_gpytorch_model(mll);\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#define acquisition function\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "#optimize\n",
    "n_steps = 45\n",
    "for i in range(n_steps):\n",
    "    #best_normed_y = torch.max(normed_train_y)\n",
    "    UCB = UpperConfidenceBound(gp, beta=2.5)\n",
    "    #EI = ExpectedImprovement(gp, best_normed_y)\n",
    "\n",
    "    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\n",
    "    candidate, acq_value = optimize_acqf(UCB, bounds = bounds, num_restarts = 20, q = 1, raw_samples = 20)\n",
    "\n",
    "    train_x = torch.cat((train_x, transformer_x.backward(candidate)))\n",
    "    normed_train_x = transformer_x.forward(train_x)\n",
    "\n",
    "    new_y = torch.tensor(evaluate(train_x[-1][0], train_x[-1][1], train_x[-1][2])).reshape(1,1)\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    \n",
    "    print(\"iteration        target         varx         vary         varz\")\n",
    "    print(f'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}')\n",
    "    print(torch.max(train_y))\n",
    "    \n",
    "    transformer_y = transformer.Transformer(train_y, 'standardize')\n",
    "    normed_train_y = transformer_y.forward(train_y)\n",
    "\n",
    "    gp = SingleTaskGP(normed_train_x, normed_train_y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_model(mll);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfb5ca-1288-468e-b19d-8360a35c94a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
