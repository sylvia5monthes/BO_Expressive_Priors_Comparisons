{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed841451-2ad2-4a82-8b8d-e8cc8904736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN Surrogate model class\n",
    "from injector_surrogate_quads import *\n",
    "import physics_gp\n",
    "\n",
    "sys.path.append('../configs')\n",
    "#Sim reference point to optimize around\n",
    "from ref_config import ref_point\n",
    "\n",
    "#Pytorch \n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import botorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9dd34-10e0-4915-accf-957a40d4f47b",
   "metadata": {},
   "source": [
    "# BO for Minimizing Emittance with 3 Variables (SQ, CQ, SOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ef807c-db73-418f-adfb-66d40cc2124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load injector model\n",
    "\n",
    "### original tf/keras model ###\n",
    "# Model = Surrogate_NN()\n",
    "\n",
    "# Model.load_saved_model(model_path = '../models/', \\\n",
    "#                        model_name = 'model_OTR2_NA_rms_emit_elu_2021-07-27T19_54_57-07_00')\n",
    "# Model.load_scaling()\n",
    "# Model.take_log_out = False\n",
    "\n",
    "### pytorch model ### \n",
    "Model = Surrogate_NN(pytorch=True)\n",
    "\n",
    "Model.load_saved_model(model_path = '../models/', \n",
    "                       model_name = 'Surrogate_NN_PyTorch')\n",
    "\n",
    "Model.load_scaling(scalerfilex = '../data/transformer_x_pytorch.pth', \n",
    "                   scalerfiley = '../data/transformer_y_pytorch.pth')\n",
    "Model.take_log_out = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d0ea5-fda2-4658-bcc0-0f89757ffeb8",
   "metadata": {},
   "source": [
    "## Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5c9f45-597a-4ac9-b809-7e91a3157c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to machine units\n",
    "ref_point = Model.sim_to_machine(np.asarray(ref_point))\n",
    "\n",
    "#input params: solenoid and quads to vary \n",
    "opt_var_names = ['SOL1:solenoid_field_scale','SQ01:b1_gradient','CQ01:b1_gradient']\n",
    "#input bounds\n",
    "bounds = torch.tensor([[0.44, 0.55],[-0.02, 0.02], [-0.02, 0.02]])\n",
    "\n",
    "#output params: emittance in transverse plane (x & y)\n",
    "opt_out_names = ['norm_emit_x','norm_emit_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712a59e5-3b68-4c92-b4d8-fc7f122feec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config): \n",
    "    \"\"\"\n",
    "    D is input space dimensionality\n",
    "    N is number of sample points\n",
    "    :param config: input values of opt_var_names, torch.tensor, shape (N, D) \n",
    "    returns (1, N) \n",
    "    \"\"\"\n",
    "    N = config.shape[0]\n",
    "    D = config.shape[1]\n",
    "    \n",
    "    # make input array of length model_in_list (inputs model takes)\n",
    "    x_in = torch.empty((N,len(Model.model_in_list)))\n",
    "    \n",
    "    # fill in reference point around which to optimize\n",
    "    x_in[:,:] = torch.as_tensor(ref_point[0])\n",
    "\n",
    "    #set solenoid, CQ, SQ, matching quads to values from optimization step\n",
    "    col = []\n",
    "    for i in range(D):\n",
    "        col.append(Model.loc_in[opt_var_names[i]]) #should make col a flat list of indices, e.g. [4, 6, 7]\n",
    "    x_in[:, col] = config[:,:] \n",
    "    \n",
    "    #output predictions\n",
    "    x_in = x_in.float()\n",
    "    y_out = Model.pred_machine_units(x_in)\n",
    "\n",
    "    return -1*objective(y_out).detach() ## !! ASK ABOUT Trying to backward through the graph a second time, but the buffers have already been freed\n",
    "\n",
    "def objective(y_out):\n",
    "    \n",
    "    #output is geometric emittance in transverse plane\n",
    "    out1 = y_out[:,Model.loc_out['norm_emit_x']] #grab norm_emit_x out of the model\n",
    "    out2 = y_out[:,Model.loc_out['norm_emit_y']] #grab norm_emit_y out of the model\n",
    "       \n",
    "    return torch.sqrt(out1*out2)/1e-6 # in um units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95895f93-be9f-4fd1-b50c-ba4d488269bb",
   "metadata": {},
   "source": [
    "## Gaussian Regression & Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3579279b-21fd-4afc-b7b3-33b0fd38ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BO_point(x, f, bounds, beta=2.0, input_transform=None, outcome_transform=None, precision = None):\n",
    "    \"\"\"\n",
    "    function that trains a GP model of data and returns the next observation point using UCB\n",
    "    D is input space dimensionality\n",
    "    N is number of samples\n",
    "\n",
    "    :param x: input points data, torch.tensor, shape (N,D)\n",
    "    :param f: output point data, torch.tensor, shape (N,1)\n",
    "    :param bounds: input space bounds, torch.tensor, shape (2,D)\n",
    "    :param precision: precision matrix used for RBF kernel (must be PSD), torch.tensor, (D,D)\n",
    "    :param beta: UCB optimization parameter, float\n",
    "    :return x_candidate, model: next observation point and gp model w/observations\n",
    "    \"\"\"\n",
    "    \n",
    "    gp = botorch.models.SingleTaskGP(x, f, \n",
    "                                     outcome_transform=outcome_transform, \n",
    "                                     input_transform=input_transform)\n",
    "        \n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    \n",
    "    # fit GP hyperparameters\n",
    "    botorch.fit.fit_gpytorch_model(mll)\n",
    "\n",
    "    # do UCB acquisition\n",
    "    UCB = botorch.acquisition.UpperConfidenceBound(gp, beta=beta)\n",
    "    candidate, acq_value = botorch.optim.optimize_acqf(UCB,\n",
    "                                                       bounds=bounds,\n",
    "                                                       q=1,\n",
    "                                                       num_restarts=20,#5\n",
    "                                                       raw_samples=20)\n",
    "    return candidate, gp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab76dc5-7177-4a05-8133-4639cf66ae38",
   "metadata": {},
   "source": [
    "## Set up initial training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8e2cc5-715b-415d-a9c4-3d92e183d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4922,  0.0072,  0.0199],\n",
      "        [ 0.5402,  0.0063, -0.0175],\n",
      "        [ 0.4577, -0.0119, -0.0158],\n",
      "        [ 0.4809,  0.0194, -0.0150],\n",
      "        [ 0.5441, -0.0109,  0.0085]])\n",
      "tensor([[-2.0875],\n",
      "        [-5.1006],\n",
      "        [-1.8745],\n",
      "        [-0.7227],\n",
      "        [-4.6886]])\n"
     ]
    }
   ],
   "source": [
    "#create initial samples within specified bounds\n",
    "n_samples = 5\n",
    "n_var = 3\n",
    "\n",
    "train_x = torch.zeros((n_samples, n_var)) \n",
    "for i in range(n_var):\n",
    "    train_x[:,i] = torch.as_tensor(np.random.uniform(bounds[i,0],bounds[i,1],(n_samples,)))\n",
    "print(train_x)\n",
    "\n",
    "train_y = evaluate(train_x).reshape(-1,1)\n",
    "print(train_y)\n",
    "\n",
    "# transformer \n",
    "transformer_x = botorch.models.transforms.input.Normalize(n_var, bounds = bounds.transpose(0,1))\n",
    "transformer_y = botorch.models.transforms.outcome.Standardize(1)\n",
    "\n",
    "normed_bounds = torch.cat((torch.zeros(1,n_var), torch.ones(1,n_var)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7ebe7-3652-467a-aabd-9c285ecc7dde",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f08ef8-0cde-4c86-8e5b-57c8ac264e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m1              -1.06831     0.46008     0.01331     -0.00933\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m2              -1.11539     0.45950     0.02000     -0.02000\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m3              -0.78095     0.47614     0.02000     0.00001\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m4              -2.08438     0.45723     0.02000     0.01371\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m5              -0.59519     0.47793     0.00867     -0.00999\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m6              -0.78877     0.47298     0.01008     -0.02000\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m7              -0.69033     0.47351     0.01614     -0.01030\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m8              -0.76370     0.48455     0.01382     -0.00602\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m9              -0.58660     0.47535     0.00648     -0.00276\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m10              -0.59452     0.47855     -0.00101     -0.00654\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m11              -0.62103     0.47423     0.00217     -0.00768\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m12              -0.56592     0.47896     0.00421     -0.00408\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m13              -0.56100     0.47720     -0.00055     -0.00064\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m14              -0.60759     0.47818     -0.00986     0.00206\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m15              -0.57713     0.48010     -0.00281     -0.00033\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m16              -0.56763     0.47652     -0.00251     -0.00052\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m17              -0.56169     0.47779     0.00092     -0.00277\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m18              -0.56405     0.47725     -0.00183     0.00312\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m19              -0.55902     0.47780     0.00129     -0.00058\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m20              -0.56083     0.47736     -0.00118     -0.00024\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m21              -0.55923     0.47791     0.00183     -0.00113\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m22              -0.56028     0.47777     -0.00158     0.00010\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m23              -0.56045     0.47783     0.00272     -0.00219\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m24              -0.57178     0.47612     -0.00325     0.00279\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m25              -0.55909     0.47804     0.00022     0.00067\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m26              -0.56135     0.47760     -0.00169     -0.00052\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m27              -0.55953     0.47760     0.00176     -0.00016\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m28              -0.56175     0.47831     -0.00219     0.00205\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m29              -0.56160     0.47790     0.00331     -0.00292\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m30              -0.56078     0.47773     -0.00154     -0.00043\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "n_steps = 30\n",
    "best_y = torch.max(train_y)\n",
    "\n",
    "for i in range(n_steps):  \n",
    "    x_new, model = get_BO_point(train_x, train_y, \n",
    "                                bounds=bounds.transpose(0,1), \n",
    "                                input_transform=transformer_x, \n",
    "                                outcome_transform=transformer_y)\n",
    "\n",
    "    train_x = torch.cat((train_x, x_new))\n",
    "    new_y = evaluate(train_x[-1].reshape(1,-1)).reshape(1,1)\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    \n",
    "    if (new_y > best_y):\n",
    "        best_y = new_y\n",
    "        color = '\\033[95m', '\\033[0m'\n",
    "    else: \n",
    "        color = '\\u001b[30m', '\\033[0m'\n",
    "    \n",
    "    print(\"iteration        target         SOL          SQ          CQ\")\n",
    "    print(f'{color[0]}{i+1}              {train_y[-1,0]:.5f}     {train_x[-1,0]:.5f}     {train_x[-1,1]:.5f}     {train_x[-1,2]:.5f}{color[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a950e-7da0-4c8c-8f01-42becd03cb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6448337-8ec1-48f0-bbae-5cd1106dbf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#define acquisition function\\nfrom botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\\nfrom botorch.optim import optimize_acqf\\n\\n#optimize\\nn_steps = 45\\nfor i in range(n_steps):\\n    #best_normed_y = torch.max(normed_train_y)\\n    UCB = UpperConfidenceBound(gp, beta=2.5)\\n    #EI = ExpectedImprovement(gp, best_normed_y)\\n\\n    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\\n    candidate, acq_value = optimize_acqf(UCB, bounds = bounds, num_restarts = 20, q = 1, raw_samples = 20)\\n\\n    train_x = torch.cat((train_x, transformer_x.backward(candidate)))\\n    normed_train_x = transformer_x.forward(train_x)\\n\\n    new_y = torch.tensor(evaluate(train_x[-1][0], train_x[-1][1], train_x[-1][2])).reshape(1,1)\\n    train_y = torch.cat((train_y, new_y))\\n    \\n    print(\"iteration        target         varx         vary         varz\")\\n    print(f\\'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}\\')\\n    print(torch.max(train_y))\\n    \\n    transformer_y = transformer.Transformer(train_y, \\'standardize\\')\\n    normed_train_y = transformer_y.forward(train_y)\\n\\n    gp = SingleTaskGP(normed_train_x, normed_train_y)\\n    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\\n    fit_gpytorch_model(mll);\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#define acquisition function\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "#optimize\n",
    "n_steps = 45\n",
    "for i in range(n_steps):\n",
    "    #best_normed_y = torch.max(normed_train_y)\n",
    "    UCB = UpperConfidenceBound(gp, beta=2.5)\n",
    "    #EI = ExpectedImprovement(gp, best_normed_y)\n",
    "\n",
    "    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\n",
    "    candidate, acq_value = optimize_acqf(UCB, bounds = bounds, num_restarts = 20, q = 1, raw_samples = 20)\n",
    "\n",
    "    train_x = torch.cat((train_x, transformer_x.backward(candidate)))\n",
    "    normed_train_x = transformer_x.forward(train_x)\n",
    "\n",
    "    new_y = torch.tensor(evaluate(train_x[-1][0], train_x[-1][1], train_x[-1][2])).reshape(1,1)\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    \n",
    "    print(\"iteration        target         varx         vary         varz\")\n",
    "    print(f'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}')\n",
    "    print(torch.max(train_y))\n",
    "    \n",
    "    transformer_y = transformer.Transformer(train_y, 'standardize')\n",
    "    normed_train_y = transformer_y.forward(train_y)\n",
    "\n",
    "    gp = SingleTaskGP(normed_train_x, normed_train_y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_model(mll);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39cfb5ca-1288-468e-b19d-8360a35c94a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 216.97930908203125\n",
      "199 148.77322387695312\n",
      "299 102.99685668945312\n",
      "399 72.24969482421875\n",
      "499 51.58010482788086\n",
      "599 37.67311096191406\n",
      "699 28.30780029296875\n",
      "799 21.995250701904297\n",
      "899 17.736312866210938\n",
      "999 14.860123634338379\n",
      "1099 12.915842056274414\n",
      "1199 11.600123405456543\n",
      "1299 10.708847045898438\n",
      "1399 10.10446548461914\n",
      "1499 9.694156646728516\n",
      "1599 9.41530990600586\n",
      "1699 9.225595474243164\n",
      "1799 9.096376419067383\n",
      "1899 9.008256912231445\n",
      "1999 8.948097229003906\n",
      "Result: y = -0.008838691748678684 + 0.8491359949111938 x + 0.0015248217387124896 x^2 + -0.09224866330623627 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\")  # Uncomment this to run on GPU\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "# By default, requires_grad=False, which indicates that we do not need to\n",
    "# compute gradients with respect to these Tensors during the backward pass.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Create random Tensors for weights. For a third order polynomial, we need\n",
    "# 4 weights: y = a + b x + c x^2 + d x^3\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "a = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y using operations on Tensors.\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
    "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51094e-24d7-4dcb-a3f5-8fa49d59a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
