{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed841451-2ad2-4a82-8b8d-e8cc8904736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN Surrogate model class\n",
    "from injector_surrogate_quads import *\n",
    "import physics_gp\n",
    "\n",
    "sys.path.append('../configs')\n",
    "#Sim reference point to optimize around\n",
    "from ref_config import ref_point\n",
    "\n",
    "#Pytorch \n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import botorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9dd34-10e0-4915-accf-957a40d4f47b",
   "metadata": {},
   "source": [
    "# BO for Minimizing Emittance with 3 Variables (SQ, CQ, SOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ef807c-db73-418f-adfb-66d40cc2124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load injector model\n",
    "\n",
    "### original tf/keras model ###\n",
    "# Model = Surrogate_NN()\n",
    "\n",
    "# Model.load_saved_model(model_path = '../models/', \\\n",
    "#                        model_name = 'model_OTR2_NA_rms_emit_elu_2021-07-27T19_54_57-07_00')\n",
    "# Model.load_scaling()\n",
    "# Model.take_log_out = False\n",
    "\n",
    "### pytorch model ### \n",
    "Model = Surrogate_NN(pytorch=True)\n",
    "\n",
    "Model.load_saved_model(model_path = '../models/', \n",
    "                       model_name = 'Surrogate_NN_PyTorch')\n",
    "\n",
    "Model.load_scaling(scalerfilex = '../data/transformer_x_pytorch.pth', \n",
    "                   scalerfiley = '../data/transformer_y_pytorch.pth')\n",
    "Model.take_log_out = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d0ea5-fda2-4658-bcc0-0f89757ffeb8",
   "metadata": {},
   "source": [
    "## Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5c9f45-597a-4ac9-b809-7e91a3157c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to machine units\n",
    "ref_point = Model.sim_to_machine(np.asarray(ref_point))\n",
    "\n",
    "#input params: solenoid and quads to vary \n",
    "opt_var_names = ['SOL1:solenoid_field_scale','SQ01:b1_gradient','CQ01:b1_gradient']\n",
    "#input bounds\n",
    "bounds = torch.tensor([[0.44, 0.55],[-0.02, 0.02], [-0.02, 0.02]])\n",
    "\n",
    "#output params: emittance in transverse plane (x & y)\n",
    "opt_out_names = ['norm_emit_x','norm_emit_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712a59e5-3b68-4c92-b4d8-fc7f122feec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed all np functions to torch for pytorch model\n",
    "def evaluate(config): \n",
    "    \"\"\"\n",
    "    D is input space dimensionality\n",
    "    N is number of sample points\n",
    "    :param config: input values of opt_var_names, torch.tensor, shape (N, D) \n",
    "    returns (1, N) \n",
    "    \"\"\"\n",
    "    N = config.shape[0]\n",
    "    D = config.shape[1]\n",
    "    \n",
    "    # make input array of length model_in_list (inputs model takes)\n",
    "    x_in = torch.empty((N,len(Model.model_in_list)))\n",
    "    \n",
    "    # fill in reference point around which to optimize\n",
    "    x_in[:,:] = torch.tensor(ref_point[0])\n",
    "\n",
    "    #set solenoid, CQ, SQ, matching quads to values from optimization step\n",
    "    col = []\n",
    "    for i in range(D):\n",
    "        col.append(Model.loc_in[opt_var_names[i]]) #should make col a flat list of indices, e.g. [4, 6, 7]\n",
    "    x_in[:, col] = config[:,:] \n",
    "    \n",
    "    #output predictions\n",
    "    y_out = Model.pred_machine_units(x_in)\n",
    "\n",
    "    return -1*objective(y_out) ## !! ASK ABOUT Trying to backward through the graph a second time, but the buffers have already been freed\n",
    "\n",
    "def objective(y_out):\n",
    "    \n",
    "    #output is geometric emittance in transverse plane\n",
    "    out1 = y_out[:,Model.loc_out['norm_emit_x']] #grab norm_emit_x out of the model\n",
    "    out2 = y_out[:,Model.loc_out['norm_emit_y']] #grab norm_emit_y out of the model\n",
    "       \n",
    "    return torch.sqrt(out1*out2)/1e-6 # in um units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95895f93-be9f-4fd1-b50c-ba4d488269bb",
   "metadata": {},
   "source": [
    "## Gaussian Regression & Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3579279b-21fd-4afc-b7b3-33b0fd38ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BO_point(x, f, bounds, beta=2.0, input_transform=None, outcome_transform=None, precision = None):\n",
    "    \"\"\"\n",
    "    function that trains a GP model of data and returns the next observation point using UCB\n",
    "    D is input space dimensionality\n",
    "    N is number of samples\n",
    "\n",
    "    :param x: input points data, torch.tensor, shape (N,D)\n",
    "    :param f: output point data, torch.tensor, shape (N,1)\n",
    "    :param bounds: input space bounds, torch.tensor, shape (2,D)\n",
    "    :param precision: precision matrix used for RBF kernel (must be PSD), torch.tensor, (D,D)\n",
    "    :param beta: UCB optimization parameter, float\n",
    "    :return x_candidate, model: next observation point and gp model w/observations\n",
    "    \"\"\"\n",
    "    \n",
    "    gp = botorch.models.SingleTaskGP(x, f, \n",
    "                                     outcome_transform=outcome_transform, \n",
    "                                     input_transform=input_transform)\n",
    "        \n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    \n",
    "    # fit GP hyperparameters\n",
    "    botorch.fit.fit_gpytorch_model(mll)\n",
    "\n",
    "    # do UCB acquisition\n",
    "    UCB = botorch.acquisition.UpperConfidenceBound(gp, beta=beta)\n",
    "    candidate, acq_value = botorch.optim.optimize_acqf(UCB,\n",
    "                                                       bounds=bounds,\n",
    "                                                       q=1,\n",
    "                                                       num_restarts=20,#5\n",
    "                                                       raw_samples=20)\n",
    "    return candidate, gp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab76dc5-7177-4a05-8133-4639cf66ae38",
   "metadata": {},
   "source": [
    "## Set up initial training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8e2cc5-715b-415d-a9c4-3d92e183d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4571,  0.0154, -0.0090],\n",
      "        [ 0.5038, -0.0149, -0.0191],\n",
      "        [ 0.5199,  0.0120, -0.0033],\n",
      "        [ 0.4752,  0.0017,  0.0185],\n",
      "        [ 0.4521, -0.0171,  0.0042]])\n",
      "tensor([[-1.2142],\n",
      "        [-3.2386],\n",
      "        [-3.3384],\n",
      "        [-0.8863],\n",
      "        [-1.5469]])\n"
     ]
    }
   ],
   "source": [
    "#create initial samples within specified bounds\n",
    "n_samples = 5\n",
    "n_var = 3\n",
    "\n",
    "train_x = torch.zeros((n_samples, n_var)) \n",
    "for i in range(n_var):\n",
    "    train_x[:,i] = torch.tensor(np.random.uniform(bounds[i,0],bounds[i,1],(n_samples,)))\n",
    "print(train_x)\n",
    "\n",
    "train_y = evaluate(train_x).detach().reshape(-1,1)\n",
    "print(train_y)\n",
    "\n",
    "# transformer \n",
    "transformer_x = botorch.models.transforms.input.Normalize(n_var, bounds = bounds.transpose(0,1))\n",
    "transformer_y = botorch.models.transforms.outcome.Standardize(1)\n",
    "\n",
    "normed_bounds = torch.cat((torch.zeros(1,n_var), torch.ones(1,n_var)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7ebe7-3652-467a-aabd-9c285ecc7dde",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f08ef8-0cde-4c86-8e5b-57c8ac264e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m1              -1.84507     0.44978     0.00658     0.01047\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m2              -0.81148     0.47503     -0.01111     0.02000\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m3              -1.80878     0.49243     -0.00743     0.02000\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m4              -1.16607     0.46360     -0.01012     0.02000\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m5              -1.85975     0.45018     0.00088     -0.02000\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m6              -0.66830     0.47241     -0.00634     0.00800\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m7              -0.70430     0.47107     0.00707     0.00091\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m8              -0.77955     0.47190     -0.00610     0.01494\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m9              -0.75651     0.47225     0.02000     -0.01036\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m10              -0.79420     0.47132     -0.00253     -0.01122\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m11              -0.76996     0.46878     0.01113     -0.00983\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m12              -0.83683     0.47250     -0.02000     0.00310\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m13              -0.56645     0.47623     -0.00075     0.00076\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m14              -0.56983     0.47746     0.00692     -0.00348\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m15              -0.57065     0.47781     0.00473     0.00200\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m16              -0.56987     0.47611     0.00369     -0.00130\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m17              -0.55952     0.47858     0.00089     -0.00089\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m18              -0.56469     0.47788     -0.00290     0.00345\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[95m19              -0.55896     0.47792     0.00126     -0.00012\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m20              -0.55987     0.47758     0.00117     0.00083\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m21              -0.55947     0.47768     0.00138     -0.00127\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m22              -0.56034     0.47751     0.00091     0.00126\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m23              -0.56163     0.47864     0.00337     -0.00069\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m24              -0.55966     0.47747     -0.00009     -0.00017\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m25              -1.72620     0.44000     -0.02000     0.02000\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m26              -0.56062     0.47747     0.00098     0.00138\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m27              -0.56021     0.47755     0.00238     -0.00152\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m28              -0.56101     0.47745     -0.00186     0.00069\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m29              -0.56004     0.47749     0.00223     -0.00035\u001b[0m\n",
      "iteration        target         SOL          SQ          CQ\n",
      "\u001b[30m30              -0.75206     0.47477     -0.02000     0.01465\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "n_steps = 30\n",
    "best_y = torch.max(train_y)\n",
    "\n",
    "for i in range(n_steps):  \n",
    "    x_new, model = get_BO_point(train_x, train_y, \n",
    "                                bounds=bounds.transpose(0,1), \n",
    "                                input_transform=transformer_x, \n",
    "                                outcome_transform=transformer_y)\n",
    "\n",
    "    train_x = torch.cat((train_x, x_new))\n",
    "    new_y = evaluate(train_x[-1].reshape(1,-1)).detach().reshape(1,1)\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    \n",
    "    if (new_y > best_y):\n",
    "        best_y = new_y\n",
    "        color = '\\033[95m', '\\033[0m'\n",
    "    else: \n",
    "        color = '\\u001b[30m', '\\033[0m'\n",
    "    \n",
    "    print(\"iteration        target         SOL          SQ          CQ\")\n",
    "    print(f'{color[0]}{i+1}              {train_y[-1,0]:.5f}     {train_x[-1,0]:.5f}     {train_x[-1,1]:.5f}     {train_x[-1,2]:.5f}{color[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a950e-7da0-4c8c-8f01-42becd03cb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6448337-8ec1-48f0-bbae-5cd1106dbf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#define acquisition function\\nfrom botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\\nfrom botorch.optim import optimize_acqf\\n\\n#optimize\\nn_steps = 45\\nfor i in range(n_steps):\\n    #best_normed_y = torch.max(normed_train_y)\\n    UCB = UpperConfidenceBound(gp, beta=2.5)\\n    #EI = ExpectedImprovement(gp, best_normed_y)\\n\\n    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\\n    candidate, acq_value = optimize_acqf(UCB, bounds = bounds, num_restarts = 20, q = 1, raw_samples = 20)\\n\\n    train_x = torch.cat((train_x, transformer_x.backward(candidate)))\\n    normed_train_x = transformer_x.forward(train_x)\\n\\n    new_y = torch.tensor(evaluate(train_x[-1][0], train_x[-1][1], train_x[-1][2])).reshape(1,1)\\n    train_y = torch.cat((train_y, new_y))\\n    \\n    print(\"iteration        target         varx         vary         varz\")\\n    print(f\\'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}\\')\\n    print(torch.max(train_y))\\n    \\n    transformer_y = transformer.Transformer(train_y, \\'standardize\\')\\n    normed_train_y = transformer_y.forward(train_y)\\n\\n    gp = SingleTaskGP(normed_train_x, normed_train_y)\\n    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\\n    fit_gpytorch_model(mll);\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#define acquisition function\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "#optimize\n",
    "n_steps = 45\n",
    "for i in range(n_steps):\n",
    "    #best_normed_y = torch.max(normed_train_y)\n",
    "    UCB = UpperConfidenceBound(gp, beta=2.5)\n",
    "    #EI = ExpectedImprovement(gp, best_normed_y)\n",
    "\n",
    "    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\n",
    "    candidate, acq_value = optimize_acqf(UCB, bounds = bounds, num_restarts = 20, q = 1, raw_samples = 20)\n",
    "\n",
    "    train_x = torch.cat((train_x, transformer_x.backward(candidate)))\n",
    "    normed_train_x = transformer_x.forward(train_x)\n",
    "\n",
    "    new_y = torch.tensor(evaluate(train_x[-1][0], train_x[-1][1], train_x[-1][2])).reshape(1,1)\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    \n",
    "    print(\"iteration        target         varx         vary         varz\")\n",
    "    print(f'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}')\n",
    "    print(torch.max(train_y))\n",
    "    \n",
    "    transformer_y = transformer.Transformer(train_y, 'standardize')\n",
    "    normed_train_y = transformer_y.forward(train_y)\n",
    "\n",
    "    gp = SingleTaskGP(normed_train_x, normed_train_y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_model(mll);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfb5ca-1288-468e-b19d-8360a35c94a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51094e-24d7-4dcb-a3f5-8fa49d59a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
