{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b7e5f-d881-45f5-88a3-738877913810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f51d051ae70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NN Surrogate model class\n",
    "import injector_surrogate_quads\n",
    "from injector_surrogate_quads import *\n",
    "import physics_gp\n",
    "import os\n",
    "\n",
    "sys.path.append('../configs')\n",
    "#Sim reference point to optimize around\n",
    "from ref_config import ref_point\n",
    "\n",
    "#Pytorch \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gpytorch\n",
    "import botorch \n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde408c-f0a8-4c90-977b-3a9ec92c4d48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BO with Expressive Priors\n",
    "### BO Minimizes Emittance*Bmag with 9 Variables (SQ, CQ, SOL, matching quads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b043b19-b9b8-4202-a7a2-e5d6a5407a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 14:23:41.676866: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load injector model\n",
    "Model = Surrogate_NN()\n",
    "\n",
    "Model.load_saved_model(model_path = '../models/', \\\n",
    "                       model_name = 'model_OTR2_NA_rms_emit_elu_2021-07-27T19_54_57-07_00')\n",
    "Model.load_scaling()\n",
    "Model.take_log_out = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b9bb0-4f3d-4151-b9d5-41d942f89bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design Twiss parameters \n",
    "beamline_info = json.load(open('../configs/beamline_info.json'))\n",
    "get_twiss0 = beamline_info['Twiss0']\n",
    "\n",
    "# emit, beta, alpha\n",
    "twiss0 = {'x': [get_twiss0[0], get_twiss0[2], get_twiss0[4]],\n",
    "          'y': [get_twiss0[1], get_twiss0[3], get_twiss0[5]]}\n",
    "\n",
    "beta0_x, alpha0_x = twiss0['x'][1], twiss0['x'][2]\n",
    "beta0_y, alpha0_y = twiss0['y'][1], twiss0['y'][2]\n",
    "# print(twiss0['x'])\n",
    "# print(twiss0['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17766e-0d89-48f8-a989-ac82e753b539",
   "metadata": {},
   "source": [
    "## Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e44ef-c047-4127-9850-1da13f8edf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to machine units\n",
    "ref_point = Model.sim_to_machine(np.asarray(ref_point))\n",
    "\n",
    "# input params: solenoid and quads to vary \n",
    "opt_var_names = ['SOL1:solenoid_field_scale','CQ01:b1_gradient', 'SQ01:b1_gradient',\n",
    "                 \"QA01:b1_gradient\", \"QA02:b1_gradient\", \n",
    "                 \"QE01:b1_gradient\", \"QE02:b1_gradient\", \"QE03:b1_gradient\", \"QE04:b1_gradient\"]\n",
    "bounds = torch.as_tensor([[0.46, 0.485], [-0.02, 0.02], [-0.02, 0.02],\n",
    "                       [-4, -1], [1, 4],\n",
    "                       [-7,-1], [-1, 7],[-1, 7], [-7, 1]])\n",
    "\n",
    "# output params: emittance in transverse plane (x & y)\n",
    "opt_out_names = ['norm_emit_x','norm_emit_y']\n",
    "\n",
    "def evaluate(config): \n",
    "    \"\"\"\n",
    "    D is input space dimensionality\n",
    "    :param config: input values of opt_var_names, torch.tensor, shape (1, D) \n",
    "    \"\"\"\n",
    "    #make input array of length model_in_list (inputs model takes)\n",
    "    x_in = np.empty((1,len(Model.model_in_list)))\n",
    "\n",
    "    #fill in reference point around which to optimize\n",
    "    x_in[:,:] = np.asarray(ref_point[0])\n",
    "\n",
    "    #set solenoid, CQ, SQ, matching quads to values from optimization step\n",
    "    for i in range(config.size(dim=0)):\n",
    "        x_in[:, Model.loc_in[opt_var_names[i]]] = config[i]\n",
    "\n",
    "    #output predictions\n",
    "    y_out = Model.pred_machine_units(x_in) \n",
    "\n",
    "    return -1*objective(y_out)[0]\n",
    "\n",
    "\n",
    "def objective(y_out):\n",
    "    # output is emittance * bmag \n",
    "    \n",
    "    # geometric emittance in transverse plane\n",
    "    out1 = y_out[:, Model.loc_out['norm_emit_x']] #grab norm_emit_x out of the model\n",
    "    out2 = y_out[:, Model.loc_out['norm_emit_y']] #grab norm_emit_y out of the model\n",
    "    emit = np.sqrt(out1 * out2)\n",
    "  \n",
    "    sigma_x = y_out[:, Model.loc_out['sigma_x']] #grab sigma_x out of the model \n",
    "    sigma_y = y_out[:, Model.loc_out['sigma_y']] #grab sigma_y out of the model \n",
    "    \n",
    "    # real beta and alpha \n",
    "    # NEEDS TO BE FIXED - currently assuming real alpha to be the same as design alpha \n",
    "    alpha_x, alpha_y = alpha0_x, alpha0_y\n",
    "    beta_x, beta_y = (sigma_x**2) / out1, (sigma_y**2) / out2\n",
    "    \n",
    "    # bmag \n",
    "    bmag_x = 0.5 * ((beta0_x / beta_x) + (beta_x / beta0_x)) + 0.5 * ((alpha_x * np.sqrt(beta0_x / beta_x) - alpha0_x * np.sqrt(beta_x / beta0_x))**2)\n",
    "    bmag_y = 0.5 * ((beta0_y / beta_y) + (beta_y / beta0_y)) + 0.5 * ((alpha_y * np.sqrt(beta0_y / beta_y) - alpha0_y * np.sqrt(beta_y / beta0_y))**2)\n",
    "    bmag = np.sqrt(bmag_x * bmag_y)\n",
    "    #print(f'bmag: {bmag} emit: {emit}') \n",
    "    \n",
    "    return (emit * bmag)/1e-6 # in um units \n",
    "    #return np.sqrt(out1*out2)/1e-6 # in um units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421056c-8737-477b-9bf4-d9a47003005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4600, -0.0200, -0.0200,  ..., -1.0000, -1.0000, -7.0000],\n",
      "        [ 0.4600, -0.0200, -0.0200,  ..., -1.0000, -1.0000, -3.0000],\n",
      "        [ 0.4600, -0.0200, -0.0200,  ..., -1.0000, -1.0000,  1.0000],\n",
      "        ...,\n",
      "        [ 0.4850,  0.0200,  0.0200,  ...,  7.0000,  7.0000, -7.0000],\n",
      "        [ 0.4850,  0.0200,  0.0200,  ...,  7.0000,  7.0000, -3.0000],\n",
      "        [ 0.4850,  0.0200,  0.0200,  ...,  7.0000,  7.0000,  1.0000]])\n",
      "torch.Size([19683, 9])\n",
      "tensor([[ -6.9780],\n",
      "        [-10.3164],\n",
      "        [ -5.1626],\n",
      "        ...,\n",
      "        [ -4.3536],\n",
      "        [ -6.9199],\n",
      "        [ -7.3886]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# mesh grid of 3^9 points to sample\n",
    "n_samples_per_var = 3\n",
    "n_var = 9\n",
    "\n",
    "\"\"\"\n",
    "create x and y if they are not saved in grid.pt, otherwise load x and y from grid.pt\n",
    "\"\"\"\n",
    "# create input and output data\n",
    "if os.path.exists('./results/grid.pt') and os.stat('./results/grid.pt').st_size > 0: \n",
    "    training_dict = torch.load('grid.pt')\n",
    "    x = training_dict['x']\n",
    "    y = training_dict['y']\n",
    "else: \n",
    "    var_points = torch.zeros((n_var, n_samples_per_var)) \n",
    "    # take n_samples_per_var points from each dimension i\n",
    "    for i in range(n_var):\n",
    "        var_points[i,:] = torch.linspace(bounds[i,0],bounds[i,1],n_samples_per_var)\n",
    "\n",
    "    # generate grid of points to sample \n",
    "    grid = np.array(np.meshgrid(*var_points)).reshape(n_var,-1)\n",
    "    x = torch.zeros((n_samples_per_var**n_var, n_var))\n",
    "    for i in range(n_samples_per_var**n_var):\n",
    "        x[i:] = torch.as_tensor(grid[:,i])\n",
    "    y = torch.as_tensor([evaluate(ele) for ele in x])\n",
    "    torch.save({'x': x, 'y': y}, 'grid.pt')\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff934db1-97f3-4773-979b-6ae392b36715",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Fit data with second order polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2ff22-d734-4bfd-8845-d6a50fcaa89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5256, -0.7502, -0.6540, -1.6095, -0.1002, -0.6092, -0.9798, -1.6091,\n",
      "         -0.7121],\n",
      "        [-0.7502,  0.3037, -0.7773, -0.2515, -0.2223,  1.6871,  0.2284,  0.4676,\n",
      "         -0.6970],\n",
      "        [-0.6540, -0.7773, -1.1608,  0.6995,  0.1991,  0.8657,  0.2444, -0.6629,\n",
      "          0.8073],\n",
      "        [-1.6095, -0.2515,  0.6995,  1.1017, -0.1759, -2.2456, -1.4465,  0.0612,\n",
      "         -1.2150],\n",
      "        [-0.1002, -0.2223,  0.1991, -0.1759,  0.7312,  1.1718, -0.9274,  0.5451,\n",
      "          0.0663],\n",
      "        [-0.6092,  1.6871,  0.8657, -2.2456,  1.1718, -0.4370,  0.7626,  1.1633,\n",
      "         -0.0091],\n",
      "        [-0.9798,  0.2284,  0.2444, -1.4465, -0.9274,  0.7626, -0.8425,  0.1374,\n",
      "          0.9386],\n",
      "        [-1.6091,  0.4676, -0.6629,  0.0612,  0.5451,  1.1633,  0.1374, -0.1860,\n",
      "         -0.6446],\n",
      "        [-0.7121, -0.6970,  0.8073, -1.2150,  0.0663, -0.0091,  0.9386, -0.6446,\n",
      "          1.5392]], requires_grad=True)\n",
      "0 20197.07253819996\n",
      "tensor([-111.2910, -137.2792, -114.0115,  ...,  -37.7810,  -73.0650,\n",
      "         -59.0932], grad_fn=<SelectBackward0>)\n",
      "50 699.1088871261485\n",
      "tensor([-33.0469, -33.2415, -16.5781,  ..., -23.5721, -35.9460, -31.4619],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "100 539.4311814409912\n",
      "tensor([-33.4387, -28.2453, -15.2882,  ..., -22.7174, -32.4726, -34.4641],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "150 465.7976547460983\n",
      "tensor([-28.9096, -22.9327, -13.7321,  ..., -20.9703, -27.6334, -31.0728],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "200 425.54223805604187\n",
      "tensor([-24.5460, -18.6254, -12.0778,  ..., -19.1234, -23.5783, -27.4062],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "250 402.22541112685946\n",
      "tensor([-21.0045, -15.3251, -10.5634,  ..., -17.4486, -20.4366, -24.3422],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "300 388.07834446148115\n",
      "tensor([-18.2434, -12.8485,  -9.2849,  ..., -16.0224, -18.0565, -21.9220],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "350 379.1156031912413\n",
      "tensor([-16.1151, -11.0056,  -8.2482,  ..., -14.8410, -16.2649, -20.0410],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# f(x) = x^T A x + B x + C\n",
    "# x is a 9x1 column vector, A is a symmetric 9x9 matrix, B is a 1x9 vector, C is a scalar.\n",
    "a_vals = torch.randn((int(n_var*(n_var+1)/2),1)).reshape(1,-1)\n",
    "A = torch.zeros(n_var, n_var)\n",
    "i, j = torch.triu_indices(n_var, n_var)\n",
    "A[i, j] = a_vals\n",
    "A.T[i, j] = a_vals\n",
    "A = A.clone().detach().requires_grad_(True)\n",
    "print(A)\n",
    "\n",
    "B = torch.randn((1, n_var), requires_grad=True)\n",
    "#print(B) \n",
    "\n",
    "C = torch.randn((1,1), requires_grad = True)\n",
    "#print(C)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for i in range(2000):\n",
    "    # if (i > 30 and i % 10 == 0 and learning_rate >= 1e-7):\n",
    "    #     learning_rate /= 10\n",
    "    y_pred = torch.cat([torch.matmul(ele, torch.matmul(A, ele.T)) + torch.matmul(B, ele.T) + C for ele in x]).reshape(1,-1)[0]\n",
    "\n",
    "    loss = (y_pred - y).pow(2).mean() #\n",
    "    if (i % 50 == 0):\n",
    "        print(i, loss.item())\n",
    "        print(y_pred)\n",
    "    #print(loss.item())\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        A -= learning_rate * A.grad\n",
    "        B -= learning_rate * B.grad\n",
    "        C -= learning_rate * C.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        A.grad = None\n",
    "        B.grad = None\n",
    "        C.grad = None\n",
    "\n",
    "print(f'Result: y = x{A}X^T + {B} x + {C.item()}')\n",
    "torch.save({'x': x, 'y': y, 'A': A, 'B': B, 'C': C, 'y_pred': y_pred}, 'grid.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bb9063-b589-42e0-be1a-e896874c74af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fit data with a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd512d49-21f0-4f0b-a07a-34919c677951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation datasets \n",
    "batch_size = 1024\n",
    "\n",
    "# transformer_x = botorch.models.transforms.input.Normalize(n_var, bounds = bounds.transpose(0,1))\n",
    "# normed_x = transformer_x.forward(x)   \n",
    "\n",
    "data = torch.utils.data.TensorDataset(x.float(), y.reshape(-1,1).float())\n",
    "#train_data = torch.utils.data.TensorDataset(normed_x.float(), y.reshape(-1,1).float())\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "valid_size = len(data) - train_size\n",
    "train_data, valid_data = torch.utils.data.random_split(data, [train_size, valid_size])\n",
    "print(len(train_data), len(valid_data))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "print(example_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796fbee5-d8d8-41f4-b714-970b324a9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "class NN_prior(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN_prior, self).__init__()\n",
    "        \n",
    "        hidden_size = 10\n",
    "        self.linear1 = nn.Linear(n_var, hidden_size)\n",
    "        self.tan1 = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tan2 = nn.Tanh()\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.tan1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.tan2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4c2df-fa14-4c5c-a130-fb3ff411dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 50\n",
    "def train_model(model, epochs, train_loader, validate_loader, optimizer):\n",
    "    \"\"\"\n",
    "    trains the NN model and tests the model on validation dataset every epoch\n",
    "    returns training and validation losses as arrays\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_valid = 1e8\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        ######### train #########\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad() \n",
    "            output = model(data) \n",
    "            \n",
    "            loss = F.mse_loss(output, target) \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step() \n",
    "            \n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "        ######### validate #########    \n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(validate_loader):\n",
    "            output = model(data) \n",
    "            valid_loss += (output - target).pow(2).sum()\n",
    "        \n",
    "        valid_loss = valid_loss / valid_size\n",
    "        valid_losses.append(valid_loss.detach()) \n",
    "        print('Valid Loss: {}'.format(valid_loss.item()))\n",
    "        \n",
    "        # save model if highest validation score # \n",
    "#         if (valid_loss < best_valid):\n",
    "#             print(\"Saved model!\")\n",
    "            \n",
    "#             best_valid = valid_loss            \n",
    "        torch.save(model.state_dict(), './results/model_1.pth') \n",
    "        torch.save(optimizer.state_dict(), './results/optimizer.pth')\n",
    "            \n",
    "    return train_losses, valid_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d169d20-b84f-4cff-ae9c-0df2dc945be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_prior_model = NN_prior()\n",
    "NN_optimizer = optim.SGD(NN_prior_model.parameters(), lr = 0.001, momentum = 0.5)\n",
    "n_epochs = 100\n",
    "train_losses, valid_losses = train_model(NN_prior_model, n_epochs, train_loader, valid_loader, NN_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb29fa-0cb5-43ea-82d3-5a71c6e9e385",
   "metadata": {},
   "source": [
    "## Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693f691-692c-4b8b-a746-63e776a86e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models  \n",
    "training_dict = torch.load('grid.pt')\n",
    "x = training_dict['x']\n",
    "y = training_dict['y']\n",
    "A = training_dict['A']\n",
    "B = training_dict['B'] \n",
    "C = training_dict['C'] \n",
    "y_pred = training_dict['y_pred']\n",
    "\n",
    "def polynomial_model(x):\n",
    "    \"\"\"\n",
    "    :param x: input values, tensor, shape (num_samples, num_var) \n",
    "    returns y_pred as tensor, shape (1, num_samples) \n",
    "    \"\"\" \n",
    "    return torch.cat([torch.matmul(ele, torch.matmul(A, ele.T)) + torch.matmul(B, ele.T) + C for ele in x.float()]).reshape(1,-1)[0]\n",
    "\n",
    "NN_model = NN_prior()\n",
    "NN_model.load_state_dict(torch.load('./results/model_1.pth'))\n",
    "NN_model.eval()\n",
    "\n",
    "print(NN_model(x[0]))\n",
    "#best = NN_y_100epochs_4hidden_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49b941-43e4-430a-b30e-7111d00d6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use ref point values for the parameters that are kept constant \n",
    "scan_ref_point = torch.cat([torch.as_tensor([ref_point[0][Model.loc_in[param_name]]]) for param_name in opt_var_names])\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "# plot loss\n",
    "i = torch.arange(100)\n",
    "#plt.plot(i, train_losses[:100], label = \"train\")\n",
    "plt.plot(i, valid_losses, label = \"valid\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "def scan(model_param, num_scans, model_prior):\n",
    "    \"\"\"\n",
    "    scans values across a single parameter of the model, keeping others constant\n",
    "    :param model_param: name of the model param that is being scanned, string, size 1 \n",
    "    :param num_scans: number of values scanned for parameter \n",
    "    returns model_test_y, polynomial_test_y of all scanned values  \n",
    "    \"\"\" \n",
    "    param_index = opt_var_names.index(model_param)\n",
    "    test_x = scan_ref_point.repeat(num_scans, 1) \n",
    "    test_x[:,param_index] = torch.linspace(bounds[param_index, 0], bounds[param_index, 1], num_scans)\n",
    "    #print(test_x)\n",
    "    \n",
    "    model_test_y = torch.as_tensor([evaluate(ele) for ele in test_x])\n",
    "    prior_test_y = model_prior(test_x.float()) \n",
    "    #prior_test_y = model_prior(F.normalize(test_x, dim = 0).float()) \n",
    "    return model_test_y, prior_test_y, test_x\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,35)\n",
    "for i in range(len(opt_var_names)):\n",
    "    model_param = opt_var_names[i] \n",
    "    model_test_y, prior_test_y, test_x = scan(model_param, 30, NN_model) \n",
    "    plt.subplot(9, 2, i+1)\n",
    "    plt.xlabel(model_param)\n",
    "    plt.ylabel('emmitance*bmag')\n",
    "    plt.plot(test_x[:,opt_var_names.index(model_param)], model_test_y, label = \"model_y\")\n",
    "    plt.plot(test_x[:,opt_var_names.index(model_param)], prior_test_y.detach(), label = \"NN_y_100epochs_2hidden_tanh\")\n",
    "    plt.legend()\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445c537-7a92-4e4c-abca-5318a2e5c97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
