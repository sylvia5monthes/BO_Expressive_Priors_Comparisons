{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "#NN Surrogate model class\n",
    "from injector_surrogate_quads import *\n",
    "import physics_gp\n",
    "\n",
    "sys.path.append('../configs')\n",
    "#Sim reference point to optimize around\n",
    "from ref_config import ref_point\n",
    "\n",
    "#Pytorch \n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import botorch \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BO for Minimizing Emittance*Bmag with 9 Variables (SQ, CQ, SOL, matching quads)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "Model = Surrogate_NN(pytorch=True)\n",
    "\n",
    "Model.load_saved_model(model_path = '../models/', \n",
    "                       model_name = 'Surrogate_NN_PyTorch')\n",
    "\n",
    "Model.load_scaling(scalerfilex = '../data/transformer_x_pytorch.pth', \n",
    "                   scalerfiley = '../data/transformer_y_pytorch.pth')\n",
    "Model.take_log_out = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import design Twiss parameters (OTR2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "beamline_info = json.load(open('../configs/beamline_info.json'))\n",
    "get_twiss0 = beamline_info['Twiss0']\n",
    "\n",
    "# emit, beta, alpha\n",
    "twiss0 = {'x': [get_twiss0[0], get_twiss0[2], get_twiss0[4]],\n",
    "          'y': [get_twiss0[1], get_twiss0[3], get_twiss0[5]]}\n",
    "\n",
    "beta0_x, alpha0_x = twiss0['x'][1], twiss0['x'][2]\n",
    "beta0_y, alpha0_y = twiss0['y'][1], twiss0['y'][2]\n",
    "# print(twiss0['x'], twiss0['y'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Objective Function"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# convert to machine units\n",
    "ref_point = Model.sim_to_machine(np.asarray(ref_point))\n",
    "\n",
    "# input params: solenoid and quads to vary \n",
    "opt_var_names = ['SOL1:solenoid_field_scale','CQ01:b1_gradient', 'SQ01:b1_gradient',\n",
    "                 \"QA01:b1_gradient\", \"QA02:b1_gradient\", \n",
    "                 \"QE01:b1_gradient\", \"QE02:b1_gradient\", \"QE03:b1_gradient\", \"QE04:b1_gradient\"]\n",
    "\n",
    "bounds = torch.as_tensor([[0.46, 0.485], [-0.02, 0.02], [-0.02, 0.02],\n",
    "                       [-4, -1], [1, 4],\n",
    "                       [-7,-1], [-1, 7],[-1, 7], [-7, 1]])\n",
    "\n",
    "# output params: emittance in transverse plane (x & y)\n",
    "opt_out_names = ['norm_emit_x','norm_emit_y']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "def evaluate(config): \n",
    "    \"\"\"\n",
    "    D is input space dimensionality\n",
    "    N is number of sample points\n",
    "    :param config: input values of opt_var_names, torch.tensor, shape (N, D) \n",
    "    returns (N, 1) \n",
    "    \"\"\"\n",
    "    N = config.shape[0]\n",
    "    D = config.shape[1]\n",
    "    \n",
    "    # make input array of length model_in_list (inputs model takes)\n",
    "    x_in = torch.empty((N,len(Model.model_in_list)))\n",
    "    \n",
    "    # fill in reference point around which to optimize\n",
    "    x_in[:,:] = torch.tensor(ref_point[0])\n",
    "\n",
    "    #set solenoid, CQ, SQ, matching quads to values from optimization step\n",
    "    col = []\n",
    "    for i in range(D):\n",
    "        col.append(Model.loc_in[opt_var_names[i]]) #should make col a flat list of indices, e.g. [4, 6, 7]\n",
    "    x_in[:, col] = config[:,:] \n",
    "    \n",
    "    #output predictions\n",
    "    y_out = Model.pred_machine_units(x_in)\n",
    "\n",
    "    return -1*objective(y_out)\n",
    "\n",
    "\n",
    "def objective(y_out):\n",
    "    \"\"\"\n",
    "    :param y_out: tensor with has a shape of (N, num_outputs)\n",
    "    returns tensor of emittance * bmag for each input, shape (N, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # geometric emittance in transverse plane\n",
    "    out1 = y_out[:,Model.loc_out['norm_emit_x']] #grab norm_emit_x out of the model\n",
    "    out2 = y_out[:,Model.loc_out['norm_emit_y']] #grab norm_emit_y out of the model\n",
    "    emit = torch.sqrt(out1 * out2)\n",
    "  \n",
    "    sigma_x = y_out[:,Model.loc_out['sigma_x']] #grab sigma_x out of the model \n",
    "    sigma_y = y_out[:,Model.loc_out['sigma_y']] #grab sigma_y out of the model \n",
    "    \n",
    "    # real beta and alpha \n",
    "    # NEEDS TO BE FIXED - currently assuming real alpha to be the same as design alpha \n",
    "    alpha_x = torch.tensor(alpha0_x).repeat(y_out.shape[0])\n",
    "    alpha_y = torch.tensor(alpha0_y).repeat(y_out.shape[0])\n",
    "    beta_x, beta_y = (sigma_x**2) / out1, (sigma_y**2) / out2\n",
    "    \n",
    "    # bmag \n",
    "    bmag_x = 0.5 * ((beta0_x / beta_x) + (beta_x / beta0_x)) + 0.5 * ((alpha_x * torch.sqrt(beta0_x / beta_x) - alpha0_x * torch.sqrt(beta_x / beta0_x))**2)\n",
    "    bmag_y = 0.5 * ((beta0_y / beta_y) + (beta_y / beta0_y)) + 0.5 * ((alpha_y * torch.sqrt(beta0_y / beta_y) - alpha0_y * torch.sqrt(beta_y / beta0_y))**2)\n",
    "    bmag = torch.sqrt(bmag_x * bmag_y)\n",
    "    \n",
    "    out = (emit * bmag)/1e-6 # in um units \n",
    "    return out.reshape(-1,1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example: Set up initial training samples"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "#create initial samples within specified bounds\n",
    "n_samples = 3\n",
    "n_var = 9\n",
    "\n",
    "train_x = torch.zeros((n_samples, n_var)) \n",
    "for i in range(n_var):\n",
    "    train_x[:,i] = torch.tensor(np.random.uniform(bounds[i,0],bounds[i,1],(n_samples,)))\n",
    "print(train_x)\n",
    "\n",
    "train_y = evaluate(train_x).detach() # detach gradient to fix going backwards twice error while fitting hyperparameters\n",
    "print(train_y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 4.8260e-01, -6.2215e-03,  1.3010e-02, -3.9893e+00,  1.9605e+00,\n",
      "         -3.3281e+00,  4.5234e+00,  3.0866e+00,  1.0145e-01],\n",
      "        [ 4.7701e-01,  5.7961e-03,  1.6276e-02, -2.8086e+00,  1.2775e+00,\n",
      "         -4.6627e+00,  2.9599e+00, -5.6142e-01, -1.0650e-01],\n",
      "        [ 4.8024e-01, -1.6504e-02, -1.8295e-02, -3.8266e+00,  1.5716e+00,\n",
      "         -4.0260e+00,  2.8927e+00,  6.8510e+00, -9.5083e-01]])\n",
      "tensor([[-2.2399],\n",
      "        [-4.8170],\n",
      "        [-1.9415]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bayesian Optimization"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gaussian Regression & Acquisition Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "def get_BO_point(x, f, bounds, beta=0.1, mean_module=None, input_transform=None, outcome_transform=None):\n",
    "    \"\"\"\n",
    "    function that trains a GP model of data and returns the next observation point using UCB\n",
    "    D is input space dimensionality\n",
    "    N is number of samples\n",
    "\n",
    "    :param x: input points data, torch.tensor, shape (N,D)\n",
    "    :param f: output point data, torch.tensor, shape (N,1)\n",
    "    :param bounds: input space bounds, torch.tensor, shape (2,D)\n",
    "    :param precision: precision matrix used for RBF kernel (must be PSD), torch.tensor, (D,D)\n",
    "    :param beta: UCB optimization parameter, float\n",
    "    :return x_candidate, model: next observation point and gp model w/observations\n",
    "    \"\"\"\n",
    "    gp = botorch.models.SingleTaskGP(x, f,\n",
    "                                     mean_module=mean_module, \n",
    "                                     outcome_transform=outcome_transform, \n",
    "                                     input_transform=input_transform)\n",
    "        \n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    \n",
    "    # fit GP hyperparameters\n",
    "    botorch.fit.fit_gpytorch_model(mll)\n",
    "\n",
    "    # do UCB acquisition\n",
    "    UCB = botorch.acquisition.UpperConfidenceBound(gp, beta=beta)\n",
    "    candidate, acq_value = botorch.optim.optimize_acqf(UCB,\n",
    "                                                       bounds=bounds,\n",
    "                                                       q=1,\n",
    "                                                       num_restarts=100,\n",
    "                                                       raw_samples=100)\n",
    "    return candidate, gp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "def BayesianOptimization(train_x, train_y, n_steps, prior=None, transformer_x=None, transformer_y=None):\n",
    "    best_y_list = []\n",
    "    best_y = torch.max(train_y)\n",
    "    best_y_list.append(best_y)\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        x_new, model = get_BO_point(train_x, train_y, \n",
    "                                    bounds=bounds.transpose(0,1), \n",
    "                                    mean_module=prior, \n",
    "                                    input_transform=transformer_x, \n",
    "                                    outcome_transform=transformer_y)\n",
    "\n",
    "        train_x = torch.cat((train_x, x_new))\n",
    "        new_y = evaluate(train_x[-1].reshape(1,-1)).detach()\n",
    "        train_y = torch.cat((train_y, new_y))\n",
    "\n",
    "        if (new_y > best_y):\n",
    "            best_y = new_y\n",
    "            color = '\\033[95m', '\\033[0m'\n",
    "        else: \n",
    "            color = '\\u001b[30m', '\\033[0m'\n",
    "        \n",
    "        best_y_list.append(best_y)\n",
    "        \n",
    "        # print(\"iter     target       SOL        CQ        SQ        QA1        QA2        Q1        Q2        Q3        Q4\")\n",
    "        # print(f'{color[0]}{i+1}      {train_y[-1,0]:.5f}   {train_x[-1,0]:.5f}   {train_x[-1,1]:.5f}   {train_x[-1,2]:.5f}   {train_x[-1,3]:.5f}   {train_x[-1,4]:.5f}   {train_x[-1,5]:.5f}   {train_x[-1,6]:.5f}   {train_x[-1,7]:.5f}   {train_x[-1,8]:.5f}{color[1]}')\n",
    "        \n",
    "    return torch.tensor(best_y_list), train_x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Custom Mean Modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# class used to create NN custom prior\n",
    "import torch.nn as nn\n",
    "class NN5_prior(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN5_prior, self).__init__()\n",
    "        \n",
    "        hidden_size = 40\n",
    "        self.network = nn.Sequential(nn.Linear(n_var, hidden_size), \n",
    "                                     nn.Tanh(), \n",
    "                                     nn.Linear(hidden_size, hidden_size), \n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(hidden_size, hidden_size), \n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(hidden_size, hidden_size),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(hidden_size, hidden_size),\n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(hidden_size, 1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x \n",
    "\n",
    "class NN4_prior(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN4_prior, self).__init__()\n",
    "        \n",
    "        hidden_size = 30\n",
    "        self.network = nn.Sequential(nn.Linear(n_var, hidden_size), \n",
    "                                     nn.Tanh(), \n",
    "                                     nn.Linear(hidden_size, hidden_size), \n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(hidden_size, hidden_size), \n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(hidden_size, hidden_size), \n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(hidden_size, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        takes in transformed x, returns transformed y\n",
    "        \"\"\"\n",
    "        x = self.network(x)\n",
    "        return x \n",
    "\n",
    "class NN3_prior(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN3_prior, self).__init__()\n",
    "        \n",
    "        hidden_size = 20\n",
    "        self.network = nn.Sequential(nn.Linear(n_var, hidden_size), \n",
    "                                     nn.Tanh(), \n",
    "                                     nn.Linear(hidden_size, hidden_size), \n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(hidden_size, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        takes in transformed x, returns transformed y\n",
    "        \"\"\"\n",
    "        x = self.network(x)\n",
    "        return x \n",
    "    \n",
    "# NN model trained from surrogate model samples as prior\n",
    "from gpytorch.means.mean import Mean\n",
    "class CustomMean(Mean):\n",
    "    def __init__(self, name, prior, NN_y_transform, outcome_transform):\n",
    "        super(CustomMean, self).__init__()\n",
    "        self.NN_model = prior\n",
    "        self.NN_model.load_state_dict(torch.load('./results/' + name + '.pth'))\n",
    "        self.NN_model.eval()\n",
    "        \n",
    "        self.NN_model.requires_grad_(False)\n",
    "        \n",
    "        self.y_norm_transform = botorch.models.transforms.input.Normalize(1)\n",
    "        self.y_norm_transform.load_state_dict(torch.load(f'./results/' + NN_y_transform + '.pth'))\n",
    "        self.y_norm_transform.eval()\n",
    "        \n",
    "        self.outcome_transform = outcome_transform\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        takes in transformed x, returns transformed y\n",
    "        \"\"\"\n",
    "        self.outcome_transform.eval()\n",
    "        \n",
    "        out = []\n",
    "        if (x.dim() == 2):\n",
    "            x = x.unsqueeze(dim=0) # shape x into (batch_size = 1, n_samples, n_var) if necessary \n",
    "        for i in range(x.size(dim=0)):\n",
    "            m = self.NN_model(x[i].detach()).float() # normed x |-> NN normed y \n",
    "            m = self.y_norm_transform.untransform(m) # NN normed y -> real y\n",
    "            m = self.outcome_transform(m)[0] # real y -> standardized y\n",
    "            out.append(m.squeeze())\n",
    "            \n",
    "        self.outcome_transform.train()\n",
    "        return torch.stack(out,dim=0)\n",
    "    \n",
    "# surrogate model as prior \n",
    "class Surrogate(Mean):\n",
    "    def __init__(self, input_transform, outcome_transform):\n",
    "        super(Surrogate, self).__init__()\n",
    "        self.input_transform = input_transform \n",
    "        self.outcome_transform = outcome_transform\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        takes in transformed x, returns transformed y (retaining gradient) \n",
    "        \"\"\"\n",
    "        self.input_transform.eval()\n",
    "        self.outcome_transform.eval()\n",
    "        \n",
    "        x = self.input_transform.untransform(x) # normed x -> real x \n",
    "        out = []\n",
    "        \n",
    "        if (x.dim() == 2):\n",
    "            x = x.unsqueeze(dim=0) # shape x into (batch_size = 1, n_samples, n_var) if necessary \n",
    "        for i in range(x.size(dim=0)):\n",
    "            m = evaluate(x[i].detach()).float() # real x |-> real y\n",
    "            m = self.outcome_transform(m)[0] # real y -> standardized y\n",
    "            out.append(m.squeeze())\n",
    "            \n",
    "        self.input_transform.train() \n",
    "        self.outcome_transform.train()\n",
    "        return torch.stack(out,dim=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BO trials"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "n_trials = 50\n",
    "n_steps = 30\n",
    "\n",
    "BO_runs = ['constant (default)','ground truth', 'model3_1hidden_20nodes_500epoch_0.02', 'model4_3hidden_30nodes_500epoch_0.01',\n",
    "          'model5_4hidden_40nodes_1000epoch_0.01_-5'] # names of runs \n",
    "\n",
    "transformer_x = botorch.models.transforms.input.Normalize(n_var, bounds = bounds.transpose(0,1))\n",
    "NN_y_transformers = ['transformer_y_3^9_norm', 'transformer_y_4^9_norm', 'transformer_y_5^9_-5_norm']\n",
    "\n",
    "filename = 'surr_const_model3_model4_0.1_ohmygoditworks'\n",
    "\n",
    "best_y_lists = [] # best y value over iterations of each run\n",
    "x_configs = [] # changes in parameter values over iterations of each run \n",
    "for i in range(len(BO_runs)):\n",
    "    best_y_lists.append([])\n",
    "    x_configs.append([])\n",
    "             \n",
    "run_BO = [True, True, True, True, False] # whether or not to run the type of BO\n",
    "\n",
    "for i in range(n_trials):\n",
    "    #for each trial, new training samples are generated, and each BO run type is executed\n",
    "    \n",
    "    train_x = torch.zeros((n_samples, n_var)) \n",
    "    for j in range(n_var):\n",
    "        train_x[:,j] = torch.tensor(np.random.uniform(bounds[j,0],bounds[j,1],(n_samples,)))\n",
    "\n",
    "    train_y = evaluate(train_x).detach().reshape(-1,1)\n",
    "    # print(train_x, train_y)\n",
    "    \n",
    "    transformer_y_list = [] # outcome_transform modules for each type of run\n",
    "    for j in range(len(BO_runs)):\n",
    "        transformer_y_list.append(botorch.models.transforms.outcome.Standardize(1))\n",
    "\n",
    "    priors = [None, Surrogate(transformer_x, transformer_y_list[1]),\n",
    "             CustomMean(BO_runs[2], NN3_prior(), NN_y_transformers[0], transformer_y_list[2]),\n",
    "             CustomMean(BO_runs[3], NN4_prior(), NN_y_transformers[1], transformer_y_list[3]),\n",
    "             CustomMean(BO_runs[4], NN5_prior(), NN_y_transformers[2], transformer_y_list[4])] # the priors used for each type of run \n",
    "        \n",
    "    print(f'iter {i}')\n",
    "    for run_index in range (len(BO_runs)):\n",
    "\n",
    "        if run_BO[run_index] == True:\n",
    "            print(f'running {BO_runs[run_index]}')\n",
    "            prior_best_y, prior_x_config = BayesianOptimization(train_x, \n",
    "                                                         train_y, \n",
    "                                                         n_steps=n_steps, \n",
    "                                                         prior=priors[run_index], \n",
    "                                                         transformer_x=transformer_x,\n",
    "                                                         transformer_y=transformer_y_list[run_index])\n",
    "            best_y_lists[run_index].append(prior_best_y)\n",
    "            x_configs[run_index] = prior_x_config\n",
    "        torch.save({'BO_runs': BO_runs, 'run_BO': run_BO, 'x_configs': x_configs, 'best_y_lists': best_y_lists}, './results/' + filename + '.pt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iter 0\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 1\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 2\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 3\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 4\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 5\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 6\n",
      "running constant (default)\n",
      "running ground truth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 7\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 8\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 9\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 10\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 11\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 12\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 13\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 14\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 15\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 16\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 17\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 18\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 19\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 20\n",
      "running constant (default)\n",
      "running ground truth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 21\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 22\n",
      "running constant (default)\n",
      "running ground truth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 23\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 24\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 25\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 26\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 27\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 28\n",
      "running constant (default)\n",
      "running ground truth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 29\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 30\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 31\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 32\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 33\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 34\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 35\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 36\n",
      "running constant (default)\n",
      "running ground truth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 37\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 38\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 39\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 40\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 41\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 42\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 43\n",
      "running constant (default)\n",
      "running ground truth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/Users/conniexu/opt/anaconda3/envs/baxenv/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 44\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 45\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 46\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 47\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 48\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n",
      "iter 49\n",
      "running constant (default)\n",
      "running ground truth\n",
      "running model3_1hidden_20nodes_500epoch_0.02\n",
      "running model4_3hidden_30nodes_500epoch_0.01\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "\"\"\"\n",
    "#define acquisition function\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "#optimize\n",
    "n_steps = 45\n",
    "for i in range(n_steps):\n",
    "    #best_normed_y = torch.max(normed_train_y)\n",
    "    UCB = UpperConfidenceBound(gp, beta=2.5)\n",
    "    #EI = ExpectedImprovement(gp, best_normed_y)\n",
    "\n",
    "    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\n",
    "    candidate, acq_value = optimize_acqf(UCB, bounds = bounds, num_restarts = 20, q = 1, raw_samples = 20)\n",
    "\n",
    "    train_x = torch.cat((train_x, transformer_x.backward(candidate)))\n",
    "    normed_train_x = transformer_x.forward(train_x)\n",
    "\n",
    "    new_y = torch.tensor(evaluate(train_x[-1][0], train_x[-1][1], train_x[-1][2])).reshape(1,1)\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    \n",
    "    print(\"iteration        target         varx         vary         varz\")\n",
    "    print(f'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}')\n",
    "    print(torch.max(train_y))\n",
    "    \n",
    "    transformer_y = transformer.Transformer(train_y, 'standardize')\n",
    "    normed_train_y = transformer_y.forward(train_y)\n",
    "\n",
    "    gp = SingleTaskGP(normed_train_x, normed_train_y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_model(mll);\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n#define acquisition function\\nfrom botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\\nfrom botorch.optim import optimize_acqf\\n\\n#optimize\\nn_steps = 45\\nfor i in range(n_steps):\\n    #best_normed_y = torch.max(normed_train_y)\\n    UCB = UpperConfidenceBound(gp, beta=2.5)\\n    #EI = ExpectedImprovement(gp, best_normed_y)\\n\\n    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\\n    candidate, acq_value = optimize_acqf(UCB, bounds = bounds, num_restarts = 20, q = 1, raw_samples = 20)\\n\\n    train_x = torch.cat((train_x, transformer_x.backward(candidate)))\\n    normed_train_x = transformer_x.forward(train_x)\\n\\n    new_y = torch.tensor(evaluate(train_x[-1][0], train_x[-1][1], train_x[-1][2])).reshape(1,1)\\n    train_y = torch.cat((train_y, new_y))\\n    \\n    print(\"iteration        target         varx         vary         varz\")\\n    print(f\\'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}\\')\\n    print(torch.max(train_y))\\n    \\n    transformer_y = transformer.Transformer(train_y, \\'standardize\\')\\n    normed_train_y = transformer_y.forward(train_y)\\n\\n    gp = SingleTaskGP(normed_train_x, normed_train_y)\\n    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\\n    fit_gpytorch_model(mll);\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.13 64-bit ('baxenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "interpreter": {
   "hash": "1b5f70a3ad72b4c9068574509e3a0dfc0f3358b3c11cb6bf99f482c84ce18336"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}