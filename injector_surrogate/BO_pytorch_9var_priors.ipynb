{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55b7e5f-d881-45f5-88a3-738877913810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2228208ad0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NN Surrogate model class\n",
    "from injector_surrogate_quads import *\n",
    "import physics_gp\n",
    "import os\n",
    "\n",
    "sys.path.append('../configs')\n",
    "#Sim reference point to optimize around\n",
    "from ref_config import ref_point\n",
    "\n",
    "#Pytorch \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gpytorch\n",
    "import botorch \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b043b19-b9b8-4202-a7a2-e5d6a5407a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 23:36:07.755118: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load injector model\n",
    "Model = Surrogate_NN()\n",
    "\n",
    "Model.load_saved_model(model_path = '../models/', \\\n",
    "                       model_name = 'model_OTR2_NA_rms_emit_elu_2021-07-27T19_54_57-07_00')\n",
    "Model.load_scaling()\n",
    "Model.take_log_out = False\n",
    "\n",
    "# print(Model.model_1.summary())\n",
    "# for layer in Model.model_1.layers:  \n",
    "#     print(layer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4b9bb0-4f3d-4151-b9d5-41d942f89bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design Twiss parameters \n",
    "beamline_info = json.load(open('../configs/beamline_info.json'))\n",
    "get_twiss0 = beamline_info['Twiss0']\n",
    "\n",
    "# emit, beta, alpha\n",
    "twiss0 = {'x': [get_twiss0[0], get_twiss0[2], get_twiss0[4]],\n",
    "          'y': [get_twiss0[1], get_twiss0[3], get_twiss0[5]]}\n",
    "\n",
    "beta0_x, alpha0_x = twiss0['x'][1], twiss0['x'][2]\n",
    "beta0_y, alpha0_y = twiss0['y'][1], twiss0['y'][2]\n",
    "# print(twiss0['x'])\n",
    "# print(twiss0['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17766e-0d89-48f8-a989-ac82e753b539",
   "metadata": {},
   "source": [
    "## Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f49e44ef-c047-4127-9850-1da13f8edf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to machine units\n",
    "ref_point = Model.sim_to_machine(np.asarray(ref_point))\n",
    "\n",
    "# input params: solenoid and quads to vary \n",
    "opt_var_names = ['SOL1:solenoid_field_scale','CQ01:b1_gradient', 'SQ01:b1_gradient',\n",
    "                 \"QA01:b1_gradient\", \"QA02:b1_gradient\", \n",
    "                 \"QE01:b1_gradient\", \"QE02:b1_gradient\", \"QE03:b1_gradient\", \"QE04:b1_gradient\"]\n",
    "bounds = torch.as_tensor([[0.46, 0.485], [-0.02, 0.02], [-0.02, 0.02],\n",
    "                       [-4, -1], [1, 4],\n",
    "                       [-7,-1], [-1, 7],[-1, 7], [-7, 1]])\n",
    "\n",
    "# output params: emittance in transverse plane (x & y)\n",
    "opt_out_names = ['norm_emit_x','norm_emit_y']\n",
    "\n",
    "def evaluate(config): \n",
    "    \"\"\"\n",
    "    D is input space dimensionality\n",
    "    N is number of sample points\n",
    "    :param config: input values of opt_var_names, torch.tensor, shape (N, D) \n",
    "    returns (1, N) \n",
    "    \"\"\"\n",
    "    N = config.shape[0]\n",
    "    D = config.shape[1]\n",
    "    \n",
    "    # make input array of length model_in_list (inputs model takes)\n",
    "    x_in = np.empty((N,len(Model.model_in_list)))\n",
    "    \n",
    "    # fill in reference point around which to optimize\n",
    "    x_in[:,:] = np.asarray(ref_point[0])\n",
    "\n",
    "    #set solenoid, CQ, SQ, matching quads to values from optimization step\n",
    "    col = []\n",
    "    for i in range(D):\n",
    "        col.append(Model.loc_in[opt_var_names[i]]) #should make col a flat list of indices, e.g. [4, 6, 7]\n",
    "    x_in[:, col] = config[:,:] \n",
    "    \n",
    "    #output predictions\n",
    "    y_out = Model.pred_machine_units(x_in)\n",
    "\n",
    "    return -1*objective(y_out)\n",
    "\n",
    "\n",
    "def objective(y_out):\n",
    "    \"\"\"\n",
    "    y_out has a shape of (M, N, num_outputs)\n",
    "    \"\"\"\n",
    "    # output is emittance * bmag \n",
    "    \n",
    "    # geometric emittance in transverse plane\n",
    "    out1 = y_out[:,Model.loc_out['norm_emit_x']] #grab norm_emit_x out of the model\n",
    "    out2 = y_out[:,Model.loc_out['norm_emit_y']] #grab norm_emit_y out of the model\n",
    "    emit = np.sqrt(out1 * out2)\n",
    "  \n",
    "    sigma_x = y_out[:,Model.loc_out['sigma_x']] #grab sigma_x out of the model \n",
    "    sigma_y = y_out[:,Model.loc_out['sigma_y']] #grab sigma_y out of the model \n",
    "    \n",
    "    # real beta and alpha \n",
    "    # NEEDS TO BE FIXED - currently assuming real alpha to be the same as design alpha \n",
    "    alpha_x = np.repeat(alpha0_x, (y_out.shape[0])) \n",
    "    alpha_y = np.repeat(alpha0_y, (y_out.shape[0]))\n",
    "    beta_x, beta_y = (sigma_x**2) / out1, (sigma_y**2) / out2\n",
    "    \n",
    "    # bmag \n",
    "    bmag_x = 0.5 * ((beta0_x / beta_x) + (beta_x / beta0_x)) + 0.5 * ((alpha_x * np.sqrt(beta0_x / beta_x) - alpha0_x * np.sqrt(beta_x / beta0_x))**2)\n",
    "    bmag_y = 0.5 * ((beta0_y / beta_y) + (beta_y / beta0_y)) + 0.5 * ((alpha_y * np.sqrt(beta0_y / beta_y) - alpha0_y * np.sqrt(beta_y / beta0_y))**2)\n",
    "    bmag = np.sqrt(bmag_x * bmag_y)\n",
    "    #print(f'bmag: {bmag} emit: {emit}') \n",
    "    \n",
    "    return (emit * bmag)/1e-6 # in um units \n",
    "    #return np.sqrt(out1*out2)/1e-6 # in um units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f421056c-8737-477b-9bf4-d9a47003005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19219, 9]) torch.Size([19219, 1])\n",
      "tensor([[ -6.9780],\n",
      "        [-10.3164],\n",
      "        [ -5.1626],\n",
      "        ...,\n",
      "        [ -4.3536],\n",
      "        [ -6.9199],\n",
      "        [ -7.3886]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# mesh grid of 3^9 points to sample\n",
    "n_samples_per_var = 3\n",
    "n_var = 9\n",
    "\n",
    "\"\"\"\n",
    "create x and y if they are not saved in grid.pt, otherwise load x and y from grid.pt\n",
    "\"\"\"\n",
    "# create input and output data\n",
    "if os.path.exists('./results/grid1.pt') and os.stat('./results/grid1.pt').st_size > 0: \n",
    "    training_dict = torch.load('./results/grid.pt')\n",
    "    x = training_dict['x']\n",
    "    y = training_dict['y']\n",
    "else: \n",
    "    var_points = torch.zeros((n_var, n_samples_per_var)) \n",
    "    # take n_samples_per_var points from each dimension i\n",
    "    for i in range(n_var):\n",
    "        var_points[i,:] = torch.linspace(bounds[i,0],bounds[i,1],n_samples_per_var)\n",
    "\n",
    "    # generate grid of points to sample \n",
    "    grid = np.array(np.meshgrid(*var_points)).reshape(n_var,-1)\n",
    "    x = torch.zeros((n_samples_per_var**n_var, n_var))\n",
    "    for i in range(n_samples_per_var**n_var):\n",
    "        x[i:] = torch.as_tensor(grid[:,i])\n",
    "    y = torch.as_tensor(evaluate(x))\n",
    "    torch.save({'x': x, 'y': y}, './results/grid1.pt')\n",
    "\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "x = x[torch.where(y > -20)[0]]\n",
    "y = y[torch.where(y > -20)[0]]\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "print(y)\n",
    "# plt.hist(y.numpy(), bins = 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bb9063-b589-42e0-be1a-e896874c74af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fit data with a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd512d49-21f0-4f0b-a07a-34919c677951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation datasets \n",
    "batch_size = 1024\n",
    "\n",
    "transformer_x = botorch.models.transforms.input.Normalize(n_var, bounds = bounds.transpose(0,1))\n",
    "normed_x = transformer_x(x)\n",
    "transformer_x.eval()\n",
    "\n",
    "transformer_y = botorch.models.transforms.input.Normalize(1)\n",
    "transformer_y.train()\n",
    "normed_y = transformer_y(y)\n",
    "print(normed_y)\n",
    "transformer_y.eval()\n",
    "print(torch.min(y), torch.max(y))\n",
    "\n",
    "torch.save(transformer_y.state_dict(), './results/transformer_y_norm.pth') \n",
    "torch.save(transformer_y.state_dict(), './results/transformer_x_norm.pth')\n",
    "\n",
    "data = torch.utils.data.TensorDataset(normed_x.float(), normed_y.float())\n",
    "\n",
    "##### if validating, create validation and training data sets #####\n",
    "train_size = int(0.8 * len(data))\n",
    "valid_size = len(data) - train_size\n",
    "train_data, valid_data = torch.utils.data.random_split(data, [train_size, valid_size])\n",
    "print(len(train_data), len(valid_data))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "#valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data)\n",
    "print(example_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796fbee5-d8d8-41f4-b714-970b324a9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "class NN_prior(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN_prior, self).__init__()\n",
    "        \n",
    "        hidden_size = 20\n",
    "        self.network = nn.Sequential(nn.Linear(n_var, hidden_size), \n",
    "                                     nn.Tanh(), \n",
    "                                     nn.Linear(hidden_size, hidden_size), \n",
    "                                     nn.Tanh(),\n",
    "                                     nn.Linear(hidden_size, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4c2df-fa14-4c5c-a130-fb3ff411dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 20\n",
    "def train_model(model, epochs, train_loader, valid_loader, optimizer):\n",
    "    \"\"\"\n",
    "    trains the NN model and tests the model on validation dataset every epoch\n",
    "    returns training and validation losses as arrays\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_valid = 1e8\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        ######### train #########\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad() \n",
    "            output = model(data) \n",
    "            \n",
    "            loss = F.mse_loss(output, target) \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step() \n",
    "            \n",
    "            if epoch % log_interval == 0 and batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "        ######### validate #########    \n",
    "#         model.eval()\n",
    "#         valid_loss = 0.0\n",
    "#         for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "#             output = model(data) \n",
    "#             valid_loss += (output - target).pow(2).sum()\n",
    "        \n",
    "#         valid_loss = valid_loss / valid_size\n",
    "#         valid_losses.append(valid_loss.detach()) \n",
    "        \n",
    "#         #save model if highest validation score \n",
    "#         if (valid_loss < best_valid):\n",
    "#             print(\"Saved model!\")\n",
    "#             best_valid = valid_loss       \n",
    "\n",
    "        torch.save(model.state_dict(), './results/model1.pth') \n",
    "        torch.save(optimizer.state_dict(), './results/optimizer.pth')\n",
    "            \n",
    "    return train_losses, valid_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d169d20-b84f-4cff-ae9c-0df2dc945be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN_prior_model = NN_prior()\n",
    "# NN_optimizer = optim.Adam(NN_prior_model.parameters(), lr = 0.01)\n",
    "# n_epochs = 750\n",
    "# train_losses, valid_losses = train_model(NN_prior_model, n_epochs, train_loader, None, NN_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb29fa-0cb5-43ea-82d3-5a71c6e9e385",
   "metadata": {},
   "source": [
    "## Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693f691-692c-4b8b-a746-63e776a86e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models  \n",
    "training_dict = torch.load('grid.pt')\n",
    "x = training_dict['x']\n",
    "y = training_dict['y']\n",
    "A = training_dict['A']\n",
    "B = training_dict['B'] \n",
    "C = training_dict['C'] \n",
    "y_pred = training_dict['y_pred']\n",
    "\n",
    "def polynomial_model(x):\n",
    "    \"\"\"\n",
    "    :param x: input values, tensor, shape (num_samples, num_var) \n",
    "    returns y_pred as tensor, shape (1, num_samples) \n",
    "    \"\"\" \n",
    "    return torch.cat([torch.matmul(ele, torch.matmul(A, ele.T)) + torch.matmul(B, ele.T) + C for ele in x.float()]).reshape(1,-1)[0]\n",
    "\n",
    "NN_model = NN_prior()\n",
    "NN_model.load_state_dict(torch.load('./results/model_1hidden_20nodes_500epoch_0.02.pth'))\n",
    "NN_model.eval()\n",
    "\n",
    "print(transformer_y.untransform(NN_model(normed_x[0])))\n",
    "#best = NN_y_100epochs_4hidden_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49b941-43e4-430a-b30e-7111d00d6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ref point values for the parameters that are kept constant \n",
    "scan_ref_point = torch.cat([torch.as_tensor([ref_point[0][Model.loc_in[param_name]]]) for param_name in opt_var_names])\n",
    "# print(scan_ref_point)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "# plot loss\n",
    "#plt.plot(valid_losses, label = \"train\")\n",
    "# plt.semilogy(valid_losses, label = \"log_valid\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "def scan(model_param, num_scans, model_prior):\n",
    "    \"\"\"\n",
    "    scans values across a single parameter of the model, keeping others constant\n",
    "    :param model_param: name of the model param that is being scanned, string, size 1 \n",
    "    :param num_scans: number of values scanned for parameter \n",
    "    returns model_test_y, polynomial_test_y of all scanned values  \n",
    "    \"\"\" \n",
    "    param_index = opt_var_names.index(model_param)\n",
    "    test_x = scan_ref_point.repeat(num_scans, 1) \n",
    "    test_x[:,param_index] = torch.linspace(bounds[param_index, 0], bounds[param_index, 1], num_scans)\n",
    "    #print(test_x)\n",
    "    \n",
    "    model_test_y = torch.as_tensor([evaluate(ele) for ele in test_x])\n",
    "    normed_prior_test_y = model_prior(transformer_x(test_x).float()) \n",
    "    # print(normed_prior_test_y)\n",
    "    prior_test_y = transformer_y.untransform(normed_prior_test_y)\n",
    "    #prior_test_y = model_prior(F.normalize(test_x, dim = 0).float()) \n",
    "    return model_test_y, prior_test_y, test_x\n",
    "\n",
    "plt.gcf().set_size_inches(15,35)\n",
    "for i in range(len(opt_var_names)):\n",
    "    model_param = opt_var_names[i] \n",
    "    model_test_y, prior_test_y, test_x = scan(model_param, 50, NN_model) \n",
    "    plt.subplot(9, 2, i+1)\n",
    "    plt.xlabel(model_param)\n",
    "    plt.ylabel('emmitance*bmag')\n",
    "    plt.plot(test_x[:,opt_var_names.index(model_param)], model_test_y, label = \"model_y\")\n",
    "    plt.plot(test_x[:,opt_var_names.index(model_param)], prior_test_y.detach(), label = \"NN_y_1000epochs_2hidden_tanh_0.02\")\n",
    "    plt.legend()\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445c537-7a92-4e4c-abca-5318a2e5c97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
