{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed841451-2ad2-4a82-8b8d-e8cc8904736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN Surrogate model class\n",
    "import injector_surrogate_quads\n",
    "from injector_surrogate_quads import *\n",
    "import physics_gp\n",
    "\n",
    "sys.path.append('../configs')\n",
    "#Sim reference point to optimize around\n",
    "from ref_config import ref_point\n",
    "\n",
    "#Pytorch \n",
    "import numpy as np\n",
    "import torch\n",
    "import transformer\n",
    "import gpytorch\n",
    "import botorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9dd34-10e0-4915-accf-957a40d4f47b",
   "metadata": {},
   "source": [
    "# BO for Minimizing Emittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ef807c-db73-418f-adfb-66d40cc2124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 12:15:48.422761: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#load injector model\n",
    "Model = Surrogate_NN()\n",
    "\n",
    "Model.load_saved_model(model_path = '../models/', \\\n",
    "                       model_name = 'model_OTR2_NA_rms_emit_elu_2021-07-27T19_54_57-07_00')\n",
    "Model.load_scaling()\n",
    "Model.take_log_out = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d0ea5-fda2-4658-bcc0-0f89757ffeb8",
   "metadata": {},
   "source": [
    "## Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712a59e5-3b68-4c92-b4d8-fc7f122feec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to machine units\n",
    "ref_point = Model.sim_to_machine(np.asarray(ref_point))\n",
    "\n",
    "#input params: solenoid and quads to vary \n",
    "opt_var_names = ['SOL1:solenoid_field_scale','SQ01:b1_gradient','CQ01:b1_gradient']\n",
    "\n",
    "#output params: emittance in transverse plane (x & y)\n",
    "opt_out_names = ['norm_emit_x','norm_emit_y']\n",
    "\n",
    "def evaluate(varx,vary,varz): \n",
    "\n",
    "    #make input array of length model_in_list (inputs model takes)\n",
    "    x_in = np.empty((1,len(Model.model_in_list)))\n",
    "\n",
    "    #fill in reference point around which to optimize\n",
    "    x_in[:,:] = np.asarray(ref_point[0])\n",
    "\n",
    "    #set solenoid, SQ, CQ to values from optimization step\n",
    "    x_in[:, Model.loc_in[opt_var_names[0]]] = varx\n",
    "    x_in[:, Model.loc_in[opt_var_names[1]]] = vary\n",
    "    x_in[:, Model.loc_in[opt_var_names[2]]] = varz\n",
    "\n",
    "    #output predictions\n",
    "    y_out = Model.pred_machine_units(x_in) \n",
    "\n",
    "    return -1*objective(y_out)[0]\n",
    "\n",
    "\n",
    "def objective(y_out):\n",
    "    \n",
    "    #output is geometric emittance in transverse plane\n",
    "    out1 = y_out[:,Model.loc_out['norm_emit_x']] #grab norm_emit_x out of the model\n",
    "    out2 = y_out[:,Model.loc_out['norm_emit_y']] #grab norm_emit_y out of the model\n",
    "       \n",
    "    return np.sqrt(out1*out2)/1e-6 # in um units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95895f93-be9f-4fd1-b50c-ba4d488269bb",
   "metadata": {},
   "source": [
    "## Gaussian Regression & Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3579279b-21fd-4afc-b7b3-33b0fd38ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BO_point(x, f, bounds, beta=2.5, phys=True):\n",
    "    \"\"\"\n",
    "\n",
    "    function that trains a GP model of data and returns the next observation point using UCB\n",
    "    D is input space dimensionality\n",
    "    N is number of samples\n",
    "\n",
    "    :param x: input points data, torch.tensor, shape (N,D)\n",
    "    :param f: output point data, torch.tensor, shape (N,1)\n",
    "    :param bounds: input space bounds, torch.tensor, shape (2,D)\n",
    "    :param precision: precision matrix used for RBF kernel (must be PSD), torch.tensor, (D,D)\n",
    "    :param beta: UCB optimization parameter, float\n",
    "    :return x_candidate, model: next observation point and gp model w/observations\n",
    "    \"\"\"\n",
    "    \n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    \n",
    "    if phys == True:\n",
    "        gp = physics_gp.PhysicsExactGPModel(x, f.flatten(), likelihood, precision)\n",
    "    else:\n",
    "        gp = botorch.models.SingleTaskGP(x, f, likelihood)\n",
    "        \n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    \n",
    "    # fit GP hyperparameters\n",
    "    #print('training hyperparameters')\n",
    "    botorch.fit.fit_gpytorch_model(mll)\n",
    "\n",
    "    # do UCB acquisition\n",
    "    #print('optimizing acquisition function')\n",
    "    UCB = botorch.acquisition.UpperConfidenceBound(gp, beta=beta)\n",
    "    candidate, acq_value = botorch.optim.optimize_acqf(UCB,\n",
    "                                                       bounds=bounds,\n",
    "                                                       q=1,\n",
    "                                                       num_restarts=20,#5\n",
    "                                                       raw_samples=20)\n",
    "    return candidate, gp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab76dc5-7177-4a05-8133-4639cf66ae38",
   "metadata": {},
   "source": [
    "## Set up initial training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab8e2cc5-715b-415d-a9c4-3d92e183d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4854, -0.0148,  0.0103],\n",
      "        [ 0.5061, -0.0150,  0.0131],\n",
      "        [ 0.5141,  0.0075,  0.0121],\n",
      "        [ 0.4656, -0.0177, -0.0177],\n",
      "        [ 0.5482,  0.0061,  0.0160]])\n",
      "tensor([[-0.9611],\n",
      "        [-2.4552],\n",
      "        [-3.0207],\n",
      "        [-1.7598],\n",
      "        [-4.8857]])\n",
      "[ 0.44 -0.02 -0.02]\n",
      "[0.55 0.02 0.02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n#create initial model\\ngp = SingleTaskGP(normed_train_x, normed_train_y)\\nmll = ExactMarginalLogLikelihood(gp.likelihood, gp)\\nfit_gpytorch_model(mll);\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specify bounds\n",
    "bounds = {'varx': (0.44, 0.55),\n",
    "          'vary': (-0.02, 0.02),\n",
    "          'varz': (-0.02, 0.02)\n",
    "         }\n",
    "\n",
    "tbounds = torch.tensor([[bounds['varx'][0], bounds['varx'][1]],[bounds['vary'][0], \n",
    "                         bounds['vary'][1]], [bounds['varz'][0], bounds['varz'][1]]])\n",
    "\n",
    "#print(bounds['varx'][0])\n",
    "#print(tbounds)\n",
    "\n",
    "diff = {'varx': bounds['varx'][1] - bounds['varx'][0],\n",
    "        'vary': bounds['vary'][1] - bounds['vary'][0],\n",
    "        'varz': bounds['varz'][1] - bounds['varz'][0]\n",
    "       }\n",
    "\n",
    "#create initial samples within specified bounds\n",
    "n_samples = 5\n",
    "train_x = torch.zeros((5, 3)) \n",
    "for i in range(3):\n",
    "    train_x[:,i] = torch.as_tensor(np.random.uniform(tbounds[i,0],tbounds[i,1],(n_samples,)))\n",
    "#train_x = torch.as_tensor(train_x).type(torch.FloatTensor)\n",
    "\n",
    "\"\"\"\n",
    "train_x = torch.rand(n_samples,3) \n",
    "train_x[:,0] = train_x[:,0] * diff['varx'] + bounds['varx'][0]\n",
    "train_x[:,1] = train_x[:,1] * diff['vary'] + bounds['vary'][0]\n",
    "train_x[:,2] = train_x[:,2] * diff['varz'] + bounds['varz'][0]\n",
    "\"\"\" \n",
    "print(train_x)\n",
    "\n",
    "train_y = torch.tensor([evaluate(vars[0], vars[1], vars[2]) for vars in train_x]).reshape(-1,1)\n",
    "print(train_y)\n",
    "\n",
    "\n",
    "#transformer \n",
    "transformer_x = transformer.Transformer(tbounds.transpose(0,1), transform_type = 'normalize')\n",
    "print(transformer_x.mins)\n",
    "print(transformer_x.maxs)\n",
    "normed_train_x = transformer_x.forward(train_x)\n",
    "\n",
    "transformer_y = transformer.Transformer(train_y, transform_type = 'standardize') \n",
    "normed_train_y = transformer_y.forward(train_y)\n",
    "\n",
    "\"\"\" \n",
    "#create initial model\n",
    "gp = SingleTaskGP(normed_train_x, normed_train_y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_model(mll);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7ebe7-3652-467a-aabd-9c285ecc7dde",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f08ef8-0cde-4c86-8e5b-57c8ac264e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration        target         varx         vary         varz\n",
      "1              -1.33343      0.45509      -0.01202      0.00472\n",
      "max = -0.96105\n",
      "iteration        target         varx         vary         varz\n",
      "2              -1.00349      0.46336      -0.02000      0.01856\n",
      "max = -0.96105\n",
      "iteration        target         varx         vary         varz\n",
      "3              -1.02088      0.46921      -0.00498      0.02000\n",
      "max = -0.96105\n",
      "iteration        target         varx         vary         varz\n",
      "4              -0.56249      0.47684      -0.00063      0.00119\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "5              -0.94685      0.46901      0.01762      -0.00123\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "6              -0.81290      0.48492      0.00865      -0.01157\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "7              -0.74685      0.48289      0.01022      0.00308\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "8              -0.81104      0.48445      -0.00656      -0.00420\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "9              -0.57595      0.47620      0.00495      -0.00477\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "10              -0.64916      0.47381      -0.01060      0.00541\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "11              -0.58945      0.47487      0.00416      0.00104\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "12              -0.56414      0.47914      0.00386      -0.00195\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "13              -0.56882      0.47617      -0.00010      -0.00196\n",
      "max = -0.56249\n",
      "iteration        target         varx         vary         varz\n",
      "14              -0.55948      0.47790      0.00233      -0.00103\n",
      "max = -0.55948\n",
      "iteration        target         varx         vary         varz\n",
      "15              -0.56079      0.47787      -0.00069      0.00215\n",
      "max = -0.55948\n",
      "iteration        target         varx         vary         varz\n",
      "16              -0.55955      0.47776      0.00225      -0.00101\n",
      "max = -0.55948\n",
      "iteration        target         varx         vary         varz\n",
      "17              -0.55953      0.47758      0.00175      -0.00074\n",
      "max = -0.55948\n",
      "iteration        target         varx         vary         varz\n",
      "18              -0.55965      0.47758      0.00201      -0.00076\n",
      "max = -0.55948\n",
      "iteration        target         varx         vary         varz\n",
      "19              -0.56192      0.47693      -0.00071      0.00094\n",
      "max = -0.55948\n",
      "iteration        target         varx         vary         varz\n",
      "20              -0.56213      0.47764      0.00416      -0.00199\n",
      "max = -0.55948\n",
      "iteration        target         varx         vary         varz\n",
      "21              -0.56108      0.47707      0.00129      -0.00096\n",
      "max = -0.55948\n",
      "iteration        target         varx         vary         varz\n",
      "22              -0.55924      0.47790      0.00101      0.00060\n",
      "max = -0.55924\n",
      "iteration        target         varx         vary         varz\n",
      "23              -0.56002      0.47754      0.00227      -0.00124\n",
      "max = -0.55924\n",
      "iteration        target         varx         vary         varz\n",
      "24              -0.56366      0.47732      -0.00130      0.00311\n",
      "max = -0.55924\n",
      "iteration        target         varx         vary         varz\n",
      "25              -0.56256      0.47673      0.00004      0.00026\n",
      "max = -0.55924\n",
      "iteration        target         varx         vary         varz\n",
      "26              -0.55910      0.47801      0.00115      0.00034\n",
      "max = -0.55910\n",
      "iteration        target         varx         vary         varz\n",
      "27              -0.56031      0.47761      0.00287      -0.00079\n",
      "max = -0.55910\n",
      "iteration        target         varx         vary         varz\n",
      "28              -0.55889      0.47793      0.00112      -0.00021\n",
      "max = -0.55889\n",
      "iteration        target         varx         vary         varz\n",
      "29              -0.56090      0.47754      0.00322      -0.00142\n",
      "max = -0.55889\n",
      "iteration        target         varx         vary         varz\n",
      "30              -0.56259      0.47672      0.00052      0.00023\n",
      "max = -0.55889\n"
     ]
    }
   ],
   "source": [
    "n_steps = 30\n",
    "for i in range(n_steps):\n",
    "    if i > 10:\n",
    "        phys_l = True\n",
    "        \n",
    "    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\n",
    "    x_new, model = get_BO_point(normed_train_x, normed_train_y, bounds=bounds, phys = False)\n",
    "    \n",
    "    train_x = torch.cat((train_x, transformer_x.backward(x_new)))\n",
    "    normed_train_x = transformer_x.forward(train_x)\n",
    "    \n",
    "    new_y = torch.tensor(evaluate(train_x[-1,0], train_x[-1,1], train_x[-1,2])).reshape(1,1)\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    normed_train_y = transformer_y.forward(train_y)\n",
    "    \n",
    "    train_x = train_x.type(torch.FloatTensor)\n",
    "    train_y = train_y.type(torch.FloatTensor)\n",
    "    \n",
    "    print(\"iteration        target         varx         vary         varz\")\n",
    "    print(f'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}')\n",
    "    print(f'max = {torch.max(train_y):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a950e-7da0-4c8c-8f01-42becd03cb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6448337-8ec1-48f0-bbae-5cd1106dbf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#define acquisition function\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound, ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "#optimize\n",
    "n_steps = 45\n",
    "for i in range(n_steps):\n",
    "    #best_normed_y = torch.max(normed_train_y)\n",
    "    UCB = UpperConfidenceBound(gp, beta=2.5)\n",
    "    #EI = ExpectedImprovement(gp, best_normed_y)\n",
    "\n",
    "    bounds = torch.cat((torch.zeros(1,3), torch.ones(1,3)), 0)\n",
    "    candidate, acq_value = optimize_acqf(UCB, bounds = bounds, num_restarts = 20, q = 1, raw_samples = 20)\n",
    "\n",
    "    train_x = torch.cat((train_x, transformer_x.backward(candidate)))\n",
    "    normed_train_x = transformer_x.forward(train_x)\n",
    "\n",
    "    new_y = torch.tensor(evaluate(train_x[-1][0], train_x[-1][1], train_x[-1][2])).reshape(1,1)\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    \n",
    "    print(\"iteration        target         varx         vary         varz\")\n",
    "    print(f'{i+1}              {train_y[-1][0]:.5f}      {train_x[-1][0]:.5f}      {train_x[-1][1]:.5f}      {train_x[-1][2]:.5f}')\n",
    "    print(torch.max(train_y))\n",
    "    \n",
    "    transformer_y = transformer.Transformer(train_y, 'standardize')\n",
    "    normed_train_y = transformer_y.forward(train_y)\n",
    "\n",
    "    gp = SingleTaskGP(normed_train_x, normed_train_y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_model(mll);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfb5ca-1288-468e-b19d-8360a35c94a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
